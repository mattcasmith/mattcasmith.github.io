<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.0">Jekyll</generator><link href="https://mattcasmith.net/feed.xml" rel="self" type="application/atom+xml" /><link href="https://mattcasmith.net/" rel="alternate" type="text/html" /><updated>2021-01-16T10:51:58+00:00</updated><id>https://mattcasmith.net/feed.xml</id><title type="html">MattCASmith</title><subtitle>A blog about cyber security and technology</subtitle><entry><title type="html">PES 5 Master League retrospective ‐ balancing realism and gameplay</title><link href="https://mattcasmith.net/2021/01/16/pro-evolution-soccer-5-master-league" rel="alternate" type="text/html" title="PES 5 Master League retrospective &amp;#8208; balancing realism and gameplay" /><published>2021-01-16T00:00:00+00:00</published><updated>2021-01-16T00:00:00+00:00</updated><id>https://mattcasmith.net/2021/01/16/pro-evolution-soccer-5-master-league</id><content type="html" xml:base="https://mattcasmith.net/2021/01/16/pro-evolution-soccer-5-master-league">&lt;p&gt;I have a rare off-topic post for you this month – something of an essay about the structure of the classic &lt;em&gt;Pro Evolution Soccer&lt;/em&gt; Master League, the differences in its modern-day equivalents, and a discussion about the delicate balance between realism and gameplay in video games more widely. Design in football games doesn’t get much attention, as the focus is normally on comparisons to the real game, so I thought this would be an interesting area to explore in a little more detail than I’ve seen before.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Pro Evolution Soccer 5&lt;/em&gt; has always been an all-time favourite of mine, but it is only now, 15 years after its initial release, that I have found the inspiration to do it justice in words. Of course, there are many reviews out there from 2005 that cover its gameplay, features, and so on, but in this post I have attempted to capture what made it so perfectly balanced and special to many fans. I hope that at the very least this will stir up some nostalgia that inspire others to dig out their copies for a match or two.&lt;/p&gt;

&lt;p style=&quot;float: left; width: 90%; padding: 5px; padding-left: 15px; padding-right: 5%; margin: 30px 0 10px 0; font-style: italic; border-left: 5px solid #ffff00; background: #ffffb9; color: #333;&quot;&gt;This isn’t something I’ve ever done before on this blog – but don’t worry, I won’t be doing this all the time and my focus will still be &lt;a href=&quot;/category/cyber-security.html&quot;&gt;cyber security&lt;/a&gt;! I just might dig up a retro game or two from time to time for and write a bit of a deep dive when the inspiration strikes me.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/wp-content/uploads/2021/01/pes-5-1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Like everyone else, I didn’t have a normal Christmas holiday this year. In my efforts to stave off boredom in the gap between Christmas and the new year, I installed an emulator and grabbed a copy of &lt;em&gt;Pro Evolution Soccer 5&lt;/em&gt; to play. I wasted a huge number of hours playing this game as a teenager, and wanted to see how it held up 15 years and three console generations later. To my surprise, I once again became addicted, and played Master League matches on a daily basis for the rest of the break.&lt;/p&gt;

&lt;p&gt;There is some nostalgia involved here, of course – both for the game and the 2005/06 football season – but there are so many things that should have driven me away: the graphics are rough round the edges, the game mechanics are unrefined, and the emulator stutters and occasionally refuses to let me run right until I reconnect my controller. With all these inconveniences, what kept me playing? And why didn’t I fire up my PlayStation 4 or PC and play one of the football games from 2020 instead?&lt;/p&gt;

&lt;p&gt;I believe the answer says a lot about design, both in football games and video games in general. I’d always considered &lt;em&gt;PES 5&lt;/em&gt;, or more generally the period between &lt;em&gt;Pro Evolution Soccer 4&lt;/em&gt; and &lt;em&gt;Pro Evolution Soccer 6&lt;/em&gt; on PlayStation 2 and Xbox, to be a high tide mark for football games. But even with this in mind when playing more modern games, I could never really pinpoint why. Returning to &lt;em&gt;PES 5&lt;/em&gt; in 2020 with fresh eyes has given me the perspective I needed to put this X factor into words.&lt;/p&gt;

&lt;h3 id=&quot;part-i-the-master-league&quot;&gt;Part I: The Master League&lt;/h3&gt;

&lt;p&gt;The reasons for &lt;em&gt;PES 5&lt;/em&gt;’s superiority lie both on and off the pitch. I’ll begin with the latter, which I believe is a masterstroke that is key to the game’s overall addictiveness. The Master League is Konami’s answer to FIFA’s Career Mode – a multi-season campaign that puts the player in charge of a club with financial responsibilities and the freedom to make transfers. However, there are some important differences that lean away from realism and integrate systems more often seen in other video game genres.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/wp-content/uploads/2021/01/pes-5-2.png&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;a-sense-of-ownership&quot;&gt;A sense of ownership&lt;/h4&gt;

&lt;p&gt;The first important difference is that the Master League’s focus is on the club, not the manager’s career. The player can either select or create a team at the beginning of the Master League, and cannot switch to another team at any point. If they choose the latter option, they choose the team’s name, design kits (which integrate with the game world better than similar features in other games due to the range of design options and general lack of licences), and select other attributes like a stadium and crowd colours.&lt;/p&gt;

&lt;p&gt;The “real” way to play the Master League is to begin with the default squad, rather than the team’s real-life players. This team, which includes fictional players like Castolo, Minanda, Stremer, and Ivarov, is largely useless in terms of ability. They take touches metres ahead of themselves, hit shots wildly off-target unless directly facing the goal at walking pace, and are outmuscled by even the smallest opponents. This means there is a natural siege mentality for the first couple of seasons, and scraping a point feels like a victory. Unlike &lt;em&gt;FIFA&lt;/em&gt;, where selecting Chelsea will mean Champions League matches in your first year in charge, it is not even possible to reach continental competition in the Master League until at least the third season, and even that is unlikely given the players initially at your disposal. This adds to the sense of progression as the player – and by extension their club – earns their place in the footballing world.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/wp-content/uploads/2021/01/pes-5-3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;All of this means the player has a far greater sense of ownership than they do in other games’ career modes, where they can take over a successful team of competent players assembled by a real-world manager. This is your club, and as the seasons progress and you slowly bring in talent during the transfer windows, each player in the squad reflects a decision you have made. It’s less realistic, but makes for a far more engaging game – something that will become a recurring theme through this post.&lt;/p&gt;

&lt;h4 id=&quot;a-football-rpg&quot;&gt;A football RPG&lt;/h4&gt;

&lt;p&gt;This culminates in a mode structured more like a football role-playing game (RPG) than a sports game. The squad is akin the player’s party, the matches are battles, and the time between is spent managing resources and organising the party in a way that increases the success rate, including keeping track of players’ development and signing new personnel where required. To help them on their way, &lt;em&gt;PES 5&lt;/em&gt; tracks and makes available quite a bit more data than even the most recent football games.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/wp-content/uploads/2021/01/pes-5-4.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;An important aspect of this is that transfers are straightforward, and are far more about affordability than negotiation, which is rarely done well in games. In this respect, the player’s focus is always on their points balance (more on that later) and earning enough to upgrade. They aren’t forced to sit through lengthy office cut scenes, playing a guessing game with an inconsistent AI to agree on a price, and being unable to sign the best players even in the cash-rich end game because of their value to their current clubs.&lt;/p&gt;

&lt;p&gt;Scouting players to sign is also more rewarding than in modern &lt;em&gt;FIFA&lt;/em&gt; or &lt;em&gt;PES&lt;/em&gt;. Players in both current games have an Overall rating, which often reduces comparison to a single statistic and makes choosing between two players, whether for a transfer or a starting position, a one-dimensional affair. &lt;em&gt;PES 5&lt;/em&gt; does not have this statistic, and the player must instead scan each player’s full attributes to gain an impression of their ability. Overlapping star diagrams like the one pictured above allow the player to directly compare six attributes when switching players, sometimes forcing an informed decision – for example, do I choose a full-back who is pacey and attacking, or powerful and defensive? It also helps that the full list of attributes is smaller than in modern games, making it easier to review them in full.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/wp-content/uploads/2021/01/pes-5-5.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The exaggerated speed and visibility with which these attributes improve also adds to the RPG-like sense of narrative and progression. After each match, the player is taken to a screen where progression points for each attribute stack up for the players that took to the pitch, and it’s hugely satisfying to see your signings’ attributes increase. It’s difficult to compare them exactly, but I believe the progression in &lt;em&gt;PES 5&lt;/em&gt; is also quicker than in games like the modern &lt;em&gt;FIFA&lt;/em&gt; series, where a player will join with an Overall rating in the 50s and take a decade to reach full potential. Once again, this is a compromise on realism for the sake of gameplay, increasing the investment that the player has in their squad and club.&lt;/p&gt;

&lt;h4 id=&quot;extreme-focus&quot;&gt;Extreme focus&lt;/h4&gt;

&lt;p&gt;However, the most important part of the Master League, and I believe has been lost in every current career mode, is the fact that it keeps the player extremely focused on a simple task: survival and development. There is no fan sentiment to monitor, no board waiting to sack you, and no possibility of a move to another club. It’s you and your created team against the world, and if they fail, you may be forced to start another game (something that once happened to me, when I foolishly signed Steven Pienaar and saved myself into a corner, ensuring bankruptcy). The risk level is comparable to that of classic arcade games.&lt;/p&gt;

&lt;p&gt;Points are the currency in PES 5, and the only number that matters is your bank account balance. You earn points by getting results: 1,000 for a win and 500 for a draw, with bonus points for each goal scored. Your players are paid an annual salary, and if you don’t have enough points to cover the wage bill at the end of the season, it’s game over. Any leftover funds can be used to sign new players, leading to something of a gamble on a mental risk-reward calculation when signing players during the mid-season transfer window – will the added talent be enough to secure the results necessary to pay the wages at the end of the season? Or will your ambition be the cause of your downfall?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/wp-content/uploads/2021/01/pes-5-6.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The focus on points and the wage bill adds real tension to the Master League, which is something that isn’t recreated in career modes with separate wage budgets. The stakes of each individual match are raised – especially towards the end of a subpar season – and while the board won’t be on your back for being knocked out of the cup, the number of matches and therefore your chance of winning points is reduced. This can lead to an intense scramble to scrape results in the last few fixtures.&lt;/p&gt;

&lt;p&gt;The points system also has the added effect of tying Master League difficulty directly to match difficulty. A greater challenge on the pitch means a lower chance of amassing points and signing star players. As a result, the focus is always on the football and never on dialogue trees, objectives, or working out how to please unseen and unpredictable parties that could cut your tenure short. This makes sense in the big picture, because no &lt;em&gt;PES&lt;/em&gt; or &lt;em&gt;FIFA&lt;/em&gt; game will ever be &lt;a href=&quot;/2019/01/25/football-manager-addictive-spreadsheet/&quot;&gt;&lt;em&gt;Football Manager&lt;/em&gt;&lt;/a&gt;, so they shouldn’t try to be. Perhaps the Master League economy is a byproduct of development limitations, but accidental or not, it is a beautifully concise system that could be discussed alongside some of history’s best gameplay loops.&lt;/p&gt;

&lt;h3 id=&quot;part-ii-core-gameplay&quot;&gt;Part II: Core gameplay&lt;/h3&gt;

&lt;p&gt;But what of the gameplay on the pitch, where the player spends most of their time? I remember marvelling at the realism of &lt;em&gt;PES 5&lt;/em&gt; back in 2005, but in retrospect it is nothing of the sort. Quick passes fly about effortlessly, players’ movements follow robotic paths, and pinball-like deflections between bodies produce some truly comedic spells of play. These issues may have been the due to the hardware of the time – there’s only so much Konami could do with physics and AI on a PlayStation 2, after all - but these compromises in the representation of real-life football also serve to make the game more fun.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/wp-content/uploads/2021/01/pes-5-7.png&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;the-beautiful-game&quot;&gt;The beautiful game&lt;/h4&gt;

&lt;p&gt;No football game before &lt;em&gt;PES 5&lt;/em&gt; – and arguably no game since – flows as fantastically as Konami’s masterpiece. Its gameplay mechanics are designed for fast, end-to-end action, with passes pinging between players with pinpoint accuracy, but ball control that is heavy enough that any attempt to break into a packed penalty area carries a real risk of losing possession without creating an opportunity. This means shooting from distance is just as viable an option, and it is possible to score some real 30-yard screamers with the more talented players of the time like Frank Lampard and Steven Gerrard.&lt;/p&gt;

&lt;p&gt;The game’s attacking balance is unmatched – you’re just as likely to score or miss with a long shot, a run through the middle, or a cross into the box – and this variety is catalysed by the aforementioned element of randomness. All those different shot types, deflections, mistakes, and rebounds add an organic unpredictability that means that even after hundreds of hours of play, players still see new situations emerge. This stops attacking and defending, even against the AI, from falling into the predictable patterns seen in many football games (like some &lt;em&gt;FIFA&lt;/em&gt; editions’ six-yard box square-pass-and-shoot goals).&lt;/p&gt;

&lt;h4 id=&quot;ai-and-momentum&quot;&gt;AI and momentum&lt;/h4&gt;

&lt;p&gt;It’s also worth taking a moment to discuss the AI, which you’ll be seeing a lot of if you choose to play the Master League mode. Simply put, &lt;em&gt;PES 5&lt;/em&gt;’s AI is a bigger challenge than any modern football game’s equivalent. Three seasons into my new campaign, I was just about winning consistently on four stars, and that still left me with the five-star mode (and the six-star mode, unlockable via the PES Shop) to take on.&lt;/p&gt;

&lt;p&gt;I believe a lack of predictability is again what makes the AI work so well – it seems to have a random element, and also encounters all the scraps and deflections that you do, which stops the player from learning that opponents will always pass in a certain direction or pattern. Perhaps this generation of football games was also slightly easier to develop AI for, in that the game engine itself was simpler, and there were fewer mechanics for the AI to have to interpret and choose between.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;PES 5&lt;/em&gt; matches also benefit from being left to run their course naturally. In 2021, football game forums are rife with complaints about alleged “momentum” mechanics – the idea that the game “wants” a certain result for entertainment value, and makes a losing team more likely to score a last-minute equaliser or pits a dominant player’s championship challengers against a team fighting relegation who seem to gain superhuman powers if the player has won too many matches recently. While I remember reading some initial murmurings about momentum at the time, &lt;em&gt;PES 5&lt;/em&gt; seems to largely let the game flow, free from artficial drama. The bulk of the “momentum” you’ll find here is in the commentary (particularly from Trevor Brooking, who seems obsessed with the word, especially following goals).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/wp-content/uploads/2021/01/pes-5-10.png&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;party-on-the-pitch&quot;&gt;Party on the pitch&lt;/h4&gt;

&lt;p&gt;Earlier, I discussed the Master League mode’s RPG-like elements, and these are also present as you take to the pitch, with the game adjusting noticeably to players’ attributes and engineering situations for them to take effect. Starting a player with less fatigue and better form is often more beneficial than starting a jaded superstar, and some abilities like the famous lofted through ball are essentially locked off until you have skilled enough players. These limitations initially led me to believe the game was much more basic than I remembered when I first picked it up, but as I acquired more talented players and began to see the effects on the pitch, I began to realise that this was just another facet of its complexity.&lt;/p&gt;

&lt;p&gt;In a similar way, a game of &lt;em&gt;PES 5&lt;/em&gt; includes several subtle, and sometimes slightly frustrating, gameplay features that digress from real football in the name of playability. Low-skill players take huge touches when controlling even the simplest pass, for example, and players almost always stumble when tackled, making it impossible to instantly win the ball back. This also seems to be the reason for one of the most often criticised occurrences, when the ball will occasionally pass through a player’s leg. This was criticised and branded unrealistic at the time – particularly by fans of the rival &lt;em&gt;FIFA&lt;/em&gt; series – but it’s really Konami rolling the D20 once more, and the attacker’s ability and luck totalling more than the defender’s (or vice versa). It can be visually jarring, but it’s the kind of nuanced feature that keeps the game flowing.&lt;/p&gt;

&lt;h4 id=&quot;straightforward-set-pieces&quot;&gt;Straightforward set pieces&lt;/h4&gt;

&lt;p&gt;Whenever a new iteration of a football game is at the drawing board, the developers need to make a decision on set pieces, and in the 2000s we saw a huge variety of systems employed. In my opinion, &lt;em&gt;PES 5&lt;/em&gt; strikes the balance better than any, again bringing player attributes to the forefront. Rather than a complicated system of giant arrows, ball contact diagrams, and &lt;a href=&quot;https://www.youtube.com/watch?v=cGd5qVouoCY&quot; target=&quot;_blank&quot;&gt;stop-the-slider mini games&lt;/a&gt;, Konami gave us three means of influencing free kicks: the initial angle, a power bar, and the application of curl with the D-pad. The result leaves the player feeling far more connected to the action – free kicks are fast, direct, and satisfying when they hit the top corner, and (as is the case with all good game design) when the player fails, they always feel as though they might do better next time with a slight change of technique.&lt;/p&gt;

&lt;p&gt;Penalties benefit from being even more straightforward. Both the player and the goalkeeper select one of nine directions – that’s it. No power bar, no stuttering run-ups or star jumps on the line, and no fancy chips down the centre. What happens next is a combination of luck and player attributes – even if the goalkeeper dives the right way, they might not keep the shot out if their skills don’t match the striker’s, and the taker always stands a chance of hitting the post or missing entirely. The way the outcome is calculated feels fair, balanced, and in sync with the rest of the match engine.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/wp-content/uploads/2021/01/pes-5-9.png&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;an-imperfect-masterpiece&quot;&gt;An imperfect masterpiece&lt;/h4&gt;

&lt;p&gt;All of this isn’t to say that &lt;em&gt;PES 5&lt;/em&gt;’s interpretation of football is perfect. Referees in particular could have used some refinement. After noticing them constantly blowing for soft fouls, sometimes nowhere near the ball, I initially held back on tackling, fearing that I’d gather bookings just as easily. But despite being massively strict on minor infringements, they seem to have no sense of whether a foul was committed by the last man. A deliberate but minor foul on a player through on goal will usually yield no card – the AI does it to me, I do it to the AI, and it essentially becomes another fair gameplay tactic.&lt;/p&gt;

&lt;p&gt;The advantage rule is also massively inconsistent, and is something modern football games undoubtedly do better. The main issue here is that the period that the referee plays advantage for tends to be very short. If an opposing player fouls my attacker and the ball happens to fall to his strike partner, the advantage icon disappears almost as soon as he controls it, meaning no free kick is awarded even if he is being tightly marked and is immediately dispossessed. There are also many times where the referee stops play when playing on would have given the attacking team a chance on goal. The advantage rule was a feature introduced in &lt;em&gt;PES 3&lt;/em&gt;, but even two editions later it was in desperate need of improvement.&lt;/p&gt;

&lt;p&gt;Finally, despite the flowing gameplay and organic deflections, the players themselves aren’t always the quickest to react to unexpected passages of play. Generally this isn’t an issue, but it can be frustrating to see a deflected clearance apparently fall into your star forward’s path, only for him to refuse to approach the ball, letting a more distant defender get there first and clean up the mess.&lt;/p&gt;

&lt;h3 id=&quot;part-iii-the-future-of-gaming&quot;&gt;Part III: The future of gaming&lt;/h3&gt;

&lt;p&gt;So, what does this analysis of a 15-year-old football game tell us about video games more broadly? I think the key message is that a compromise between realism and gameplay, which used to be forced upon developers by the PlayStation 2’s limited hardware, is essential to creating a more playable game. The conversation around sports games always seems to be around which title more closely resembles the real game, but perhaps the focus would be better placed on which is more fun instead.&lt;/p&gt;

&lt;p&gt;While this post has examined &lt;em&gt;PES 5&lt;/em&gt;, the same is true of games in other genres. Looking at another Konami series, &lt;em&gt;Metal Gear Solid&lt;/em&gt; evolved in a similar way. &lt;em&gt;Metal Gear Solid 2&lt;/em&gt; and &lt;em&gt;3&lt;/em&gt; were arguably the series’ peak, when gameplay was constrained to small areas that presented controlled, isolated challenges, and a large amount of effort was spent adding colour, story, and character. Fast forward to &lt;em&gt;Metal Gear Solid 5&lt;/em&gt; and emphasis is squarely on open-world gameplay, with few cut scenes and little memorable dialogue. Anybody from the mid-2000s would be stunned at the gameplay features, but the game loses its focus, both thematically and in terms of the gameplay – there are any number of situations the developers did not account for where the player can engineer situations that &lt;a href=&quot;https://www.youtube.com/watch?v=uxjnMR2CupA&quot; target=&quot;_blank&quot;&gt;confuse the AI&lt;/a&gt;, either exposing bugs (and breaking immersion) or lowering the difficulty. It is a game in desperate need of focus, both in terms of the player experience and where development time was allocated.&lt;/p&gt;

&lt;h4 id=&quot;gameplay-over-realism&quot;&gt;Gameplay over realism&lt;/h4&gt;

&lt;p&gt;A niche more commonly explored by mid-level and indie developers is the game that has fairly simple mechanics (or at least features that have been relatively stable for years) and modern graphics. This section of the gaming market is wide-ranging, but I would point to examples like &lt;em&gt;Football Manager&lt;/em&gt;, the rebooted &lt;em&gt;Hitman series&lt;/em&gt;, and the modern &lt;em&gt;Wolfenstein&lt;/em&gt; and &lt;em&gt;Doom&lt;/em&gt; games. These games follow almost the same core gameplay formula that similar titles did 15 years ago, but the developers have used the extra power at their disposal to make them prettier, refine mechanics, and improve their AI, rather than adding additional complexity unnecessarily or targeting hyperrealism at the expense of player enjoyment.&lt;/p&gt;

&lt;p&gt;In the football genre in particular, I suspect there are many disenfranchised players out there who like me would jump at the chance to play a game similar to the classic &lt;em&gt;PES&lt;/em&gt; titles, but with minor improvements (for example, updated graphics, better referees, and more consistent player control) rather than additional features that increase realism but make the game more of a chore to play (slower, heavier gameplay; player complaints and conversations, press conferences and negotiation cut scenes).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;PES&lt;/em&gt; has improved somewhat during the PS4/Xbox One generation, but it definitely isn’t as fast or addictive as it was previously, and the Master League has been diluted massively in pursuit of &lt;em&gt;FIFA&lt;/em&gt;’s Career Mode. With the focus on cash-generating online services like FIFA Ultimate Team and MyClub, gameplay has remained relatively consistent for a while now, but perhaps there’s a small developer out there that could make take a chance on a simpler, more arcadey title that resembles a refined classic &lt;em&gt;PES&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Until then, I’m hooked once more on the classic &lt;em&gt;Pro Evolution Soccer&lt;/em&gt; formula, and at least for the foreseeable future, &lt;em&gt;PES 5&lt;/em&gt; is going to remain my football game of choice.&lt;/p&gt;</content><author><name>mattcasmith</name></author><summary type="html">I have a rare off-topic post for you this month – something of an essay about the structure of the classic Pro Evolution Soccer Master League, the differences in its modern-day equivalents, and a discussion about the delicate balance between realism and gameplay in video games more widely. Design in football games doesn’t get much attention, as the focus is normally on comparisons to the real game, so I thought this would be an interesting area to explore in a little more detail than I’ve seen before. Pro Evolution Soccer 5 has always been an all-time favourite of mine, but it is only now, 15 years after its initial release, that I have found the inspiration to do it justice in words. Of course, there are many reviews out there from 2005 that cover its gameplay, features, and so on, but in this post I have attempted to capture what made it so perfectly balanced and special to many fans. I hope that at the very least this will stir up some nostalgia that inspire others to dig out their copies for a match or two. This isn’t something I’ve ever done before on this blog – but don’t worry, I won’t be doing this all the time and my focus will still be cyber security! I just might dig up a retro game or two from time to time for and write a bit of a deep dive when the inspiration strikes me. Like everyone else, I didn’t have a normal Christmas holiday this year. In my efforts to stave off boredom in the gap between Christmas and the new year, I installed an emulator and grabbed a copy of Pro Evolution Soccer 5 to play. I wasted a huge number of hours playing this game as a teenager, and wanted to see how it held up 15 years and three console generations later. To my surprise, I once again became addicted, and played Master League matches on a daily basis for the rest of the break. There is some nostalgia involved here, of course – both for the game and the 2005/06 football season – but there are so many things that should have driven me away: the graphics are rough round the edges, the game mechanics are unrefined, and the emulator stutters and occasionally refuses to let me run right until I reconnect my controller. With all these inconveniences, what kept me playing? And why didn’t I fire up my PlayStation 4 or PC and play one of the football games from 2020 instead? I believe the answer says a lot about design, both in football games and video games in general. I’d always considered PES 5, or more generally the period between Pro Evolution Soccer 4 and Pro Evolution Soccer 6 on PlayStation 2 and Xbox, to be a high tide mark for football games. But even with this in mind when playing more modern games, I could never really pinpoint why. Returning to PES 5 in 2020 with fresh eyes has given me the perspective I needed to put this X factor into words. Part I: The Master League The reasons for PES 5’s superiority lie both on and off the pitch. I’ll begin with the latter, which I believe is a masterstroke that is key to the game’s overall addictiveness. The Master League is Konami’s answer to FIFA’s Career Mode – a multi-season campaign that puts the player in charge of a club with financial responsibilities and the freedom to make transfers. However, there are some important differences that lean away from realism and integrate systems more often seen in other video game genres. A sense of ownership The first important difference is that the Master League’s focus is on the club, not the manager’s career. The player can either select or create a team at the beginning of the Master League, and cannot switch to another team at any point. If they choose the latter option, they choose the team’s name, design kits (which integrate with the game world better than similar features in other games due to the range of design options and general lack of licences), and select other attributes like a stadium and crowd colours. The “real” way to play the Master League is to begin with the default squad, rather than the team’s real-life players. This team, which includes fictional players like Castolo, Minanda, Stremer, and Ivarov, is largely useless in terms of ability. They take touches metres ahead of themselves, hit shots wildly off-target unless directly facing the goal at walking pace, and are outmuscled by even the smallest opponents. This means there is a natural siege mentality for the first couple of seasons, and scraping a point feels like a victory. Unlike FIFA, where selecting Chelsea will mean Champions League matches in your first year in charge, it is not even possible to reach continental competition in the Master League until at least the third season, and even that is unlikely given the players initially at your disposal. This adds to the sense of progression as the player – and by extension their club – earns their place in the footballing world. All of this means the player has a far greater sense of ownership than they do in other games’ career modes, where they can take over a successful team of competent players assembled by a real-world manager. This is your club, and as the seasons progress and you slowly bring in talent during the transfer windows, each player in the squad reflects a decision you have made. It’s less realistic, but makes for a far more engaging game – something that will become a recurring theme through this post. A football RPG This culminates in a mode structured more like a football role-playing game (RPG) than a sports game. The squad is akin the player’s party, the matches are battles, and the time between is spent managing resources and organising the party in a way that increases the success rate, including keeping track of players’ development and signing new personnel where required. To help them on their way, PES 5 tracks and makes available quite a bit more data than even the most recent football games. An important aspect of this is that transfers are straightforward, and are far more about affordability than negotiation, which is rarely done well in games. In this respect, the player’s focus is always on their points balance (more on that later) and earning enough to upgrade. They aren’t forced to sit through lengthy office cut scenes, playing a guessing game with an inconsistent AI to agree on a price, and being unable to sign the best players even in the cash-rich end game because of their value to their current clubs. Scouting players to sign is also more rewarding than in modern FIFA or PES. Players in both current games have an Overall rating, which often reduces comparison to a single statistic and makes choosing between two players, whether for a transfer or a starting position, a one-dimensional affair. PES 5 does not have this statistic, and the player must instead scan each player’s full attributes to gain an impression of their ability. Overlapping star diagrams like the one pictured above allow the player to directly compare six attributes when switching players, sometimes forcing an informed decision – for example, do I choose a full-back who is pacey and attacking, or powerful and defensive? It also helps that the full list of attributes is smaller than in modern games, making it easier to review them in full. The exaggerated speed and visibility with which these attributes improve also adds to the RPG-like sense of narrative and progression. After each match, the player is taken to a screen where progression points for each attribute stack up for the players that took to the pitch, and it’s hugely satisfying to see your signings’ attributes increase. It’s difficult to compare them exactly, but I believe the progression in PES 5 is also quicker than in games like the modern FIFA series, where a player will join with an Overall rating in the 50s and take a decade to reach full potential. Once again, this is a compromise on realism for the sake of gameplay, increasing the investment that the player has in their squad and club. Extreme focus However, the most important part of the Master League, and I believe has been lost in every current career mode, is the fact that it keeps the player extremely focused on a simple task: survival and development. There is no fan sentiment to monitor, no board waiting to sack you, and no possibility of a move to another club. It’s you and your created team against the world, and if they fail, you may be forced to start another game (something that once happened to me, when I foolishly signed Steven Pienaar and saved myself into a corner, ensuring bankruptcy). The risk level is comparable to that of classic arcade games. Points are the currency in PES 5, and the only number that matters is your bank account balance. You earn points by getting results: 1,000 for a win and 500 for a draw, with bonus points for each goal scored. Your players are paid an annual salary, and if you don’t have enough points to cover the wage bill at the end of the season, it’s game over. Any leftover funds can be used to sign new players, leading to something of a gamble on a mental risk-reward calculation when signing players during the mid-season transfer window – will the added talent be enough to secure the results necessary to pay the wages at the end of the season? Or will your ambition be the cause of your downfall? The focus on points and the wage bill adds real tension to the Master League, which is something that isn’t recreated in career modes with separate wage budgets. The stakes of each individual match are raised – especially towards the end of a subpar season – and while the board won’t be on your back for being knocked out of the cup, the number of matches and therefore your chance of winning points is reduced. This can lead to an intense scramble to scrape results in the last few fixtures. The points system also has the added effect of tying Master League difficulty directly to match difficulty. A greater challenge on the pitch means a lower chance of amassing points and signing star players. As a result, the focus is always on the football and never on dialogue trees, objectives, or working out how to please unseen and unpredictable parties that could cut your tenure short. This makes sense in the big picture, because no PES or FIFA game will ever be Football Manager, so they shouldn’t try to be. Perhaps the Master League economy is a byproduct of development limitations, but accidental or not, it is a beautifully concise system that could be discussed alongside some of history’s best gameplay loops. Part II: Core gameplay But what of the gameplay on the pitch, where the player spends most of their time? I remember marvelling at the realism of PES 5 back in 2005, but in retrospect it is nothing of the sort. Quick passes fly about effortlessly, players’ movements follow robotic paths, and pinball-like deflections between bodies produce some truly comedic spells of play. These issues may have been the due to the hardware of the time – there’s only so much Konami could do with physics and AI on a PlayStation 2, after all - but these compromises in the representation of real-life football also serve to make the game more fun. The beautiful game No football game before PES 5 – and arguably no game since – flows as fantastically as Konami’s masterpiece. Its gameplay mechanics are designed for fast, end-to-end action, with passes pinging between players with pinpoint accuracy, but ball control that is heavy enough that any attempt to break into a packed penalty area carries a real risk of losing possession without creating an opportunity. This means shooting from distance is just as viable an option, and it is possible to score some real 30-yard screamers with the more talented players of the time like Frank Lampard and Steven Gerrard. The game’s attacking balance is unmatched – you’re just as likely to score or miss with a long shot, a run through the middle, or a cross into the box – and this variety is catalysed by the aforementioned element of randomness. All those different shot types, deflections, mistakes, and rebounds add an organic unpredictability that means that even after hundreds of hours of play, players still see new situations emerge. This stops attacking and defending, even against the AI, from falling into the predictable patterns seen in many football games (like some FIFA editions’ six-yard box square-pass-and-shoot goals). AI and momentum It’s also worth taking a moment to discuss the AI, which you’ll be seeing a lot of if you choose to play the Master League mode. Simply put, PES 5’s AI is a bigger challenge than any modern football game’s equivalent. Three seasons into my new campaign, I was just about winning consistently on four stars, and that still left me with the five-star mode (and the six-star mode, unlockable via the PES Shop) to take on. I believe a lack of predictability is again what makes the AI work so well – it seems to have a random element, and also encounters all the scraps and deflections that you do, which stops the player from learning that opponents will always pass in a certain direction or pattern. Perhaps this generation of football games was also slightly easier to develop AI for, in that the game engine itself was simpler, and there were fewer mechanics for the AI to have to interpret and choose between. PES 5 matches also benefit from being left to run their course naturally. In 2021, football game forums are rife with complaints about alleged “momentum” mechanics – the idea that the game “wants” a certain result for entertainment value, and makes a losing team more likely to score a last-minute equaliser or pits a dominant player’s championship challengers against a team fighting relegation who seem to gain superhuman powers if the player has won too many matches recently. While I remember reading some initial murmurings about momentum at the time, PES 5 seems to largely let the game flow, free from artficial drama. The bulk of the “momentum” you’ll find here is in the commentary (particularly from Trevor Brooking, who seems obsessed with the word, especially following goals). Party on the pitch Earlier, I discussed the Master League mode’s RPG-like elements, and these are also present as you take to the pitch, with the game adjusting noticeably to players’ attributes and engineering situations for them to take effect. Starting a player with less fatigue and better form is often more beneficial than starting a jaded superstar, and some abilities like the famous lofted through ball are essentially locked off until you have skilled enough players. These limitations initially led me to believe the game was much more basic than I remembered when I first picked it up, but as I acquired more talented players and began to see the effects on the pitch, I began to realise that this was just another facet of its complexity. In a similar way, a game of PES 5 includes several subtle, and sometimes slightly frustrating, gameplay features that digress from real football in the name of playability. Low-skill players take huge touches when controlling even the simplest pass, for example, and players almost always stumble when tackled, making it impossible to instantly win the ball back. This also seems to be the reason for one of the most often criticised occurrences, when the ball will occasionally pass through a player’s leg. This was criticised and branded unrealistic at the time – particularly by fans of the rival FIFA series – but it’s really Konami rolling the D20 once more, and the attacker’s ability and luck totalling more than the defender’s (or vice versa). It can be visually jarring, but it’s the kind of nuanced feature that keeps the game flowing. Straightforward set pieces Whenever a new iteration of a football game is at the drawing board, the developers need to make a decision on set pieces, and in the 2000s we saw a huge variety of systems employed. In my opinion, PES 5 strikes the balance better than any, again bringing player attributes to the forefront. Rather than a complicated system of giant arrows, ball contact diagrams, and stop-the-slider mini games, Konami gave us three means of influencing free kicks: the initial angle, a power bar, and the application of curl with the D-pad. The result leaves the player feeling far more connected to the action – free kicks are fast, direct, and satisfying when they hit the top corner, and (as is the case with all good game design) when the player fails, they always feel as though they might do better next time with a slight change of technique. Penalties benefit from being even more straightforward. Both the player and the goalkeeper select one of nine directions – that’s it. No power bar, no stuttering run-ups or star jumps on the line, and no fancy chips down the centre. What happens next is a combination of luck and player attributes – even if the goalkeeper dives the right way, they might not keep the shot out if their skills don’t match the striker’s, and the taker always stands a chance of hitting the post or missing entirely. The way the outcome is calculated feels fair, balanced, and in sync with the rest of the match engine. An imperfect masterpiece All of this isn’t to say that PES 5’s interpretation of football is perfect. Referees in particular could have used some refinement. After noticing them constantly blowing for soft fouls, sometimes nowhere near the ball, I initially held back on tackling, fearing that I’d gather bookings just as easily. But despite being massively strict on minor infringements, they seem to have no sense of whether a foul was committed by the last man. A deliberate but minor foul on a player through on goal will usually yield no card – the AI does it to me, I do it to the AI, and it essentially becomes another fair gameplay tactic. The advantage rule is also massively inconsistent, and is something modern football games undoubtedly do better. The main issue here is that the period that the referee plays advantage for tends to be very short. If an opposing player fouls my attacker and the ball happens to fall to his strike partner, the advantage icon disappears almost as soon as he controls it, meaning no free kick is awarded even if he is being tightly marked and is immediately dispossessed. There are also many times where the referee stops play when playing on would have given the attacking team a chance on goal. The advantage rule was a feature introduced in PES 3, but even two editions later it was in desperate need of improvement. Finally, despite the flowing gameplay and organic deflections, the players themselves aren’t always the quickest to react to unexpected passages of play. Generally this isn’t an issue, but it can be frustrating to see a deflected clearance apparently fall into your star forward’s path, only for him to refuse to approach the ball, letting a more distant defender get there first and clean up the mess. Part III: The future of gaming So, what does this analysis of a 15-year-old football game tell us about video games more broadly? I think the key message is that a compromise between realism and gameplay, which used to be forced upon developers by the PlayStation 2’s limited hardware, is essential to creating a more playable game. The conversation around sports games always seems to be around which title more closely resembles the real game, but perhaps the focus would be better placed on which is more fun instead. While this post has examined PES 5, the same is true of games in other genres. Looking at another Konami series, Metal Gear Solid evolved in a similar way. Metal Gear Solid 2 and 3 were arguably the series’ peak, when gameplay was constrained to small areas that presented controlled, isolated challenges, and a large amount of effort was spent adding colour, story, and character. Fast forward to Metal Gear Solid 5 and emphasis is squarely on open-world gameplay, with few cut scenes and little memorable dialogue. Anybody from the mid-2000s would be stunned at the gameplay features, but the game loses its focus, both thematically and in terms of the gameplay – there are any number of situations the developers did not account for where the player can engineer situations that confuse the AI, either exposing bugs (and breaking immersion) or lowering the difficulty. It is a game in desperate need of focus, both in terms of the player experience and where development time was allocated. Gameplay over realism A niche more commonly explored by mid-level and indie developers is the game that has fairly simple mechanics (or at least features that have been relatively stable for years) and modern graphics. This section of the gaming market is wide-ranging, but I would point to examples like Football Manager, the rebooted Hitman series, and the modern Wolfenstein and Doom games. These games follow almost the same core gameplay formula that similar titles did 15 years ago, but the developers have used the extra power at their disposal to make them prettier, refine mechanics, and improve their AI, rather than adding additional complexity unnecessarily or targeting hyperrealism at the expense of player enjoyment. In the football genre in particular, I suspect there are many disenfranchised players out there who like me would jump at the chance to play a game similar to the classic PES titles, but with minor improvements (for example, updated graphics, better referees, and more consistent player control) rather than additional features that increase realism but make the game more of a chore to play (slower, heavier gameplay; player complaints and conversations, press conferences and negotiation cut scenes). PES has improved somewhat during the PS4/Xbox One generation, but it definitely isn’t as fast or addictive as it was previously, and the Master League has been diluted massively in pursuit of FIFA’s Career Mode. With the focus on cash-generating online services like FIFA Ultimate Team and MyClub, gameplay has remained relatively consistent for a while now, but perhaps there’s a small developer out there that could make take a chance on a simpler, more arcadey title that resembles a refined classic PES. Until then, I’m hooked once more on the classic Pro Evolution Soccer formula, and at least for the foreseeable future, PES 5 is going to remain my football game of choice.</summary></entry><entry><title type="html">Introducing Backutil: A Python‐based Windows backup utility</title><link href="https://mattcasmith.net/2021/01/01/backutil-windows-backup-utility" rel="alternate" type="text/html" title="Introducing Backutil&amp;#58; A Python&amp;#8208;based Windows backup utility" /><published>2021-01-01T00:00:00+00:00</published><updated>2021-01-01T00:00:00+00:00</updated><id>https://mattcasmith.net/2021/01/01/backutil-python-windows-backup-utility%20-%20Copy</id><content type="html" xml:base="https://mattcasmith.net/2021/01/01/backutil-windows-backup-utility">&lt;p&gt;Back in the spring, I decided that 2020 would be the year I would finally see a coding project through to completion. A recent work project shone a light on backup and recovery, and I realised that I should probably be a bit more consistent with my own backups from my personal PC. Wanting to avoid paying &lt;em&gt;another&lt;/em&gt; annual subscription, I decided to write a script myself. Thus Backutil was born - and the project only grew from there as I added more features along the way.&lt;/p&gt;

&lt;p&gt;I’m still not quite at the point when I’m ready to release a v1.0, but I told myself a few months ago that I wanted to put together a minimum viable product by the new year - so here it is! It has a few bugs and is missing a couple of features, but Backutil is now a functioning Python-based utility for backing up files on Windows systems, complete with options for incremental backups and backup rotation.&lt;/p&gt;

&lt;h3 id=&quot;contents&quot;&gt;Contents&lt;/h3&gt;

&lt;p&gt;1. &lt;a href=&quot;#introduction&quot;&gt;Introduction&lt;/a&gt;&lt;br /&gt;
          a. &lt;a href=&quot;#testing-and-limitations&quot;&gt;Testing and limitations&lt;/a&gt;&lt;br /&gt;
2. &lt;a href=&quot;#configuration&quot;&gt;Configuration&lt;/a&gt;&lt;br /&gt;
          a. &lt;a href=&quot;#configuration-file&quot;&gt;Configuration file&lt;/a&gt;&lt;br /&gt;
          b. &lt;a href=&quot;#backup-list-file&quot;&gt;Backup list file&lt;/a&gt;&lt;br /&gt;
          a. &lt;a href=&quot;#command-line-options&quot;&gt;Command line options&lt;/a&gt;&lt;br /&gt;
3. &lt;a href=&quot;#download&quot;&gt;Download&lt;/a&gt;&lt;br /&gt;
4. &lt;a href=&quot;#future-development&quot;&gt;Future development&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;introduction&quot;&gt;Introduction&lt;/h3&gt;

&lt;p&gt;Backutil is a simple, Python-based utility for backing up files from Windows systems to compressed, password-protected local archives. It has features for performing incremental backups and automatically rotating backup files. This is achieved using &lt;code&gt;robocopy&lt;/code&gt; and 7-Zip, which must be installed.&lt;/p&gt;

&lt;p style=&quot;float: left; width: 90%; padding: 5px; padding-left: 15px; padding-right: 5%; margin: 30px 0 10px 0; font-style: italic; border-left: 5px solid red; background: #ff9999; color: #333;&quot;&gt;Backutil is a learning/hobby project and some aspects of its code may not follow best practices. While you're welcome to use it, you do so at your own risk. Make sure you take a manual backup of your files before trying it out, and don't go relying on it to back up your production servers.&lt;/p&gt;

&lt;p&gt;To back up your files, simply ensure you have configured Backutil (see the sections below) and run &lt;code&gt;backutil.exe&lt;/code&gt; from the Command Prompt or PowerShell. The utility will report on its progress until the backup is successfully completed. More detail can also be found in &lt;code&gt;backutil_log.csv&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/wp-content/uploads/2020/12/backutil-1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;When the utility is finished, you should find your complete backup files in your designated backup folder. The number and size of these backup files can be configured using the incremental backup and rotation settings, which are set in the configuration file or as command line options.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/wp-content/uploads/2020/12/backutil-2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As Backutil automatically manages your backup files, it can be configured to run automatically at the desired interval using the Windows Task Scheduler. Backutil’s features can be used to generate rolling full or incremental backups as required by your backup objectives and disk size.&lt;/p&gt;

&lt;h4 id=&quot;testing-and-limitations&quot;&gt;Testing and limitations&lt;/h4&gt;

&lt;p&gt;Aside from all the testing that comes naturally during the development process, I have been using Backutil to back up my personal files for the last month or so using a Windows scheduled task to run the utility on a weekly basis. My configuration performs incremental backups on a five-file rotation and so far has worked without a hitch, to a level where I occasionally even forgot it was running.&lt;/p&gt;

&lt;p&gt;One slight limitation, which will be improved with &lt;a href=&quot;#future-development&quot;&gt;future development&lt;/a&gt;, is the speed of the backup process. My current backups include around 83GB of data (about 50GB once compressed), and the initial “big” backup can take a couple of hours to run. For this reason, I recommend using Backutil to back up a focused set of directories rather than your whole hard drive, at least for the moment.&lt;/p&gt;

&lt;h3 id=&quot;configuration&quot;&gt;Configuration&lt;/h3&gt;

&lt;p&gt;Backutil can be configured via three main means: a configuration file, a file containing a list of directories to be backed up, and a series of command line options that override other settings. If a configuration file and backup list file are present, Backutil can be run using the following simple command.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;\&lt;span class=&quot;n&quot;&gt;backutil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exe&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;In terms of an installation directory, I put the executable and configuration files in &lt;code&gt;C:\backutil\bin\&lt;/code&gt; and use &lt;code&gt;C:\backutil\&lt;/code&gt; as the staging folder for the temporary files and records. However, you can put these files wherever you like as long as your settings are configured accordingly.&lt;/p&gt;

&lt;h4 id=&quot;configuration-file&quot;&gt;Configuration file&lt;/h4&gt;

&lt;p&gt;Backutil automatically loads settings from a file named &lt;code&gt;config.ini&lt;/code&gt;, including the location of the list of directories to back up, folders for backups and temporary files, and incremental backup and rotation options. The configuration file should be located in the same folder as &lt;code&gt;backutil.exe&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The contents of an example configuration file are shown below.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LOCAL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;computer_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pc&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;backup_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backup&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;txt&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;staging_folder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;\&lt;span class=&quot;n&quot;&gt;backutil&lt;/span&gt;\
&lt;span class=&quot;n&quot;&gt;archive_pass&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;supersecretpassword&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;incremental&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;rotation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;retained&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SERVER&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;server_directory&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;\&lt;span class=&quot;n&quot;&gt;backups&lt;/span&gt;\&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The table below sets out what each option in the &lt;code&gt;config.ini&lt;/code&gt; configuration file does. Note that all directories supplied via the configuration file must include the trailing backslash.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Section&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Key&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Purpose&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;LOCAL&lt;/td&gt;
      &lt;td&gt;computer_name&lt;/td&gt;
      &lt;td&gt;Sets backup folder/record name&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;LOCAL&lt;/td&gt;
      &lt;td&gt;backup_list&lt;/td&gt;
      &lt;td&gt;Sets the backup list filename&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;LOCAL&lt;/td&gt;
      &lt;td&gt;staging_folder&lt;/td&gt;
      &lt;td&gt;Sets folder for temporary file storage&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;LOCAL&lt;/td&gt;
      &lt;td&gt;archive_pass&lt;/td&gt;
      &lt;td&gt;Sets 7-Zip backup file password&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;LOCAL&lt;/td&gt;
      &lt;td&gt;incremental&lt;/td&gt;
      &lt;td&gt;Turns incremental backups on/off (True/False)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;LOCAL&lt;/td&gt;
      &lt;td&gt;rotation&lt;/td&gt;
      &lt;td&gt;Turns backup rotation on/off (True/False)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;LOCAL&lt;/td&gt;
      &lt;td&gt;retained&lt;/td&gt;
      &lt;td&gt;Sets number of backups to retain if rotation is on&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;SERVER&lt;/td&gt;
      &lt;td&gt;server_directory&lt;/td&gt;
      &lt;td&gt;Sets folder for backup storage&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;backup-list-file&quot;&gt;Backup list file&lt;/h4&gt;

&lt;p&gt;The backup list file is a text file containing a list of directories. When Backutil is run, it will automatically generate a list of files to back up by scanning the contents of these directories and all subdirectories. The format of the backup list file should look something like the example below.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Users&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Matt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Desktop&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Users&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Matt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Downloads&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Users&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Matt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Music&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iTunes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iTunes&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Media&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Music&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Users&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Matt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pictures&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Users&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Matt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Videos&lt;/span&gt;
 &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Note the empty line at the end of the list of directories. As of v0.51, this is required to ensure that Backutil parses the backup list file correctly (this has been noted as a bug for future development).&lt;/p&gt;

&lt;h4 id=&quot;command-line-options&quot;&gt;Command line options&lt;/h4&gt;

&lt;p&gt;Backutil also supports several options if you wish to set certain configuration parameters manually from the Command Prompt or PowerShell. Note that any parameters set via command line options will override the respective parameters in the &lt;code&gt;config.ini&lt;/code&gt; configuration file.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Short&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Long&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Purpose&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;-h&lt;/td&gt;
      &lt;td&gt;--help&lt;/td&gt;
      &lt;td&gt;Displays the help file&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;-n &amp;lt;name&amp;gt;&lt;/td&gt;
      &lt;td&gt;--name &amp;lt;name&amp;gt;&lt;/td&gt;
      &lt;td&gt;Manually sets the backup folder/record name&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;-l &amp;lt;file&amp;gt;&lt;/td&gt;
      &lt;td&gt;--list &amp;lt;file&amp;gt;&lt;/td&gt;
      &lt;td&gt;Manually sets the backup list file&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;-i&lt;/td&gt;
      &lt;td&gt;--incremental&lt;/td&gt;
      &lt;td&gt;Manually turns on incremental backups&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;-r &amp;lt;no&amp;gt;&lt;/td&gt;
      &lt;td&gt;--rotate &amp;lt;no&amp;gt;&lt;/td&gt;
      &lt;td&gt;Manually turns on backup rotation and sets number of backups&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The following command shows an example of how the command line options may be used.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;\&lt;span class=&quot;n&quot;&gt;backutil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exe&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;locations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;txt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Running Backutil with the options above will save backup files to a folder called &lt;code&gt;matts-pc&lt;/code&gt; (note that this folder name is also how previous backups are tracked). The list of directories to back up files from will be retrieved from &lt;code&gt;locations.txt&lt;/code&gt;. Backups will be incremental (only changed files will be backed up each time Backutil runs) and five previous backups will be retained.&lt;/p&gt;

&lt;h3 id=&quot;download&quot;&gt;Download&lt;/h3&gt;

&lt;p&gt;Use the link below to download Backutil. You’re free to run it for personal use - just please let me know if you encounter any bugs so I can work on fixing them in future realeases!&lt;/p&gt;

&lt;p style=&quot;float: left; width: 90%; padding: 5px; padding-left: 15px; padding-right: 5%; margin: 30px 0 10px 0; font-style: italic; border-left: 5px solid red; background: #ff9999; color: #333;&quot;&gt;Backutil is a learning/hobby project and some aspects of its code may not follow best practices. While you're welcome to use it, you do so at your own risk. Make sure you take a manual backup of your files before trying it out, and don't go relying on it to back up your production servers.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/mattcasmith/backutil/raw/main/dist/backutil_v0.51.zip&quot;&gt;&lt;img src=&quot;/assets/images/download.png&quot; style=&quot;width: 50px&quot; /&gt;&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/mattcasmith/backutil/raw/main/dist/backutil_v0.51.zip&quot;&gt;Download Backutil v0.51&lt;/a&gt;&lt;br /&gt;36.6MB, ZIP&lt;/td&gt;
      &lt;td&gt;The downloadable archive contains &lt;code&gt;backutil.exe&lt;/code&gt; and an example &lt;code&gt;config.ini&lt;/code&gt; file. Interested in the source code? The full Python script is available in &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/mattcasmith/backutil&quot;&gt;the Backutil GitHub repository&lt;/a&gt;.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;future-development&quot;&gt;Future development&lt;/h3&gt;

&lt;p&gt;My determination to build a minimum viable product before the end of 2020 means that I have a backlog of bug fixes and new features to add during 2021. These include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Speed/efficiency improvements&lt;/strong&gt; - As it stands, Backutil generates hashes and copies files via some fairly simple logic. As a next step I hope to implement a multithreading solution to process multiple files at once and reduce the time taken to perform each backup.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Improved data storage&lt;/strong&gt; - Backutil currently remembers what it has already backed up by recording file hashes in &lt;code&gt;.back&lt;/code&gt; text files. I’d like to implement a more sophisticated system that stores this data in a more structured database, likely using SQLite.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Inconsistencies and bug fixes&lt;/strong&gt; - The more time you spend with a piece of code, the more flaws you find in it. So far my list includes inconsistencies in the &lt;code&gt;--help&lt;/code&gt; output and improvements to the way the 7-Zip archive is generated, but I’m sure I’ll spot more along the way as I build other features.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Remote backups&lt;/strong&gt; - You’ll notice that some parts of Backutil use terminology associated with remote backups (for example, the &lt;code&gt;Server&lt;/code&gt; section in the configuration file). This is because Backutil could originally be configured to use WinSCP to send backup files to a remote server. This has been removed for the initial release, but I hope to reinstate it in a future version.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Graphical user interface (GUI)&lt;/strong&gt; - I’ve played around with Python GUIs a couple of times before, but have never had a script worth implementing one for. Depending on time limitations, I might develop a GUI for Backutil to increase ease of use for less experienced users.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Have you got more ideas for new Backutil features? Or have you found bugs that I haven’t? Please &lt;a href=&quot;mailto:mattcasmith@protonmail.com&quot;&gt;send me an email&lt;/a&gt; to let me know so I can add them to the development backlog.&lt;/p&gt;

&lt;p&gt;If you’re interested in the project, check back regularly for new releases. I’ll also announce any updates on &lt;a target=&quot;_blank&quot; href=&quot;https://twitter.com/mattcasmith&quot;&gt;my Twitter account&lt;/a&gt;, and may add some form of banner to &lt;a href=&quot;https://mattcasmith.net&quot;&gt;my site’s homepage&lt;/a&gt;.&lt;/p&gt;</content><author><name>mattcasmith</name></author><summary type="html">Back in the spring, I decided that 2020 would be the year I would finally see a coding project through to completion. A recent work project shone a light on backup and recovery, and I realised that I should probably be a bit more consistent with my own backups from my personal PC. Wanting to avoid paying another annual subscription, I decided to write a script myself. Thus Backutil was born - and the project only grew from there as I added more features along the way. I’m still not quite at the point when I’m ready to release a v1.0, but I told myself a few months ago that I wanted to put together a minimum viable product by the new year - so here it is! It has a few bugs and is missing a couple of features, but Backutil is now a functioning Python-based utility for backing up files on Windows systems, complete with options for incremental backups and backup rotation. Contents 1. Introduction           a. Testing and limitations 2. Configuration           a. Configuration file           b. Backup list file           a. Command line options 3. Download 4. Future development Introduction Backutil is a simple, Python-based utility for backing up files from Windows systems to compressed, password-protected local archives. It has features for performing incremental backups and automatically rotating backup files. This is achieved using robocopy and 7-Zip, which must be installed. Backutil is a learning/hobby project and some aspects of its code may not follow best practices. While you're welcome to use it, you do so at your own risk. Make sure you take a manual backup of your files before trying it out, and don't go relying on it to back up your production servers. To back up your files, simply ensure you have configured Backutil (see the sections below) and run backutil.exe from the Command Prompt or PowerShell. The utility will report on its progress until the backup is successfully completed. More detail can also be found in backutil_log.csv. When the utility is finished, you should find your complete backup files in your designated backup folder. The number and size of these backup files can be configured using the incremental backup and rotation settings, which are set in the configuration file or as command line options. As Backutil automatically manages your backup files, it can be configured to run automatically at the desired interval using the Windows Task Scheduler. Backutil’s features can be used to generate rolling full or incremental backups as required by your backup objectives and disk size. Testing and limitations Aside from all the testing that comes naturally during the development process, I have been using Backutil to back up my personal files for the last month or so using a Windows scheduled task to run the utility on a weekly basis. My configuration performs incremental backups on a five-file rotation and so far has worked without a hitch, to a level where I occasionally even forgot it was running. One slight limitation, which will be improved with future development, is the speed of the backup process. My current backups include around 83GB of data (about 50GB once compressed), and the initial “big” backup can take a couple of hours to run. For this reason, I recommend using Backutil to back up a focused set of directories rather than your whole hard drive, at least for the moment. Configuration Backutil can be configured via three main means: a configuration file, a file containing a list of directories to be backed up, and a series of command line options that override other settings. If a configuration file and backup list file are present, Backutil can be run using the following simple command. .\backutil.exe In terms of an installation directory, I put the executable and configuration files in C:\backutil\bin\ and use C:\backutil\ as the staging folder for the temporary files and records. However, you can put these files wherever you like as long as your settings are configured accordingly. Configuration file Backutil automatically loads settings from a file named config.ini, including the location of the list of directories to back up, folders for backups and temporary files, and incremental backup and rotation options. The configuration file should be located in the same folder as backutil.exe. The contents of an example configuration file are shown below. [LOCAL] computer_name = matts-pc backup_list = backup-list.txt staging_folder = C:\backutil\ archive_pass = supersecretpassword incremental = True rotation = True retained = 5 [SERVER] server_directory = D:\backups\ The table below sets out what each option in the config.ini configuration file does. Note that all directories supplied via the configuration file must include the trailing backslash. Section Key Purpose LOCAL computer_name Sets backup folder/record name LOCAL backup_list Sets the backup list filename LOCAL staging_folder Sets folder for temporary file storage LOCAL archive_pass Sets 7-Zip backup file password LOCAL incremental Turns incremental backups on/off (True/False) LOCAL rotation Turns backup rotation on/off (True/False) LOCAL retained Sets number of backups to retain if rotation is on SERVER server_directory Sets folder for backup storage Backup list file The backup list file is a text file containing a list of directories. When Backutil is run, it will automatically generate a list of files to back up by scanning the contents of these directories and all subdirectories. The format of the backup list file should look something like the example below. C:/Users/Matt/Desktop C:/Users/Matt/Downloads C:/Users/Matt/Music/iTunes/iTunes Media/Music C:/Users/Matt/Pictures C:/Users/Matt/Videos Note the empty line at the end of the list of directories. As of v0.51, this is required to ensure that Backutil parses the backup list file correctly (this has been noted as a bug for future development). Command line options Backutil also supports several options if you wish to set certain configuration parameters manually from the Command Prompt or PowerShell. Note that any parameters set via command line options will override the respective parameters in the config.ini configuration file. Short Long Purpose -h --help Displays the help file -n &amp;lt;name&amp;gt; --name &amp;lt;name&amp;gt; Manually sets the backup folder/record name -l &amp;lt;file&amp;gt; --list &amp;lt;file&amp;gt; Manually sets the backup list file -i --incremental Manually turns on incremental backups -r &amp;lt;no&amp;gt; --rotate &amp;lt;no&amp;gt; Manually turns on backup rotation and sets number of backups The following command shows an example of how the command line options may be used. .\backutil.exe -n matts-pc -l locations.txt -i -r 5 Running Backutil with the options above will save backup files to a folder called matts-pc (note that this folder name is also how previous backups are tracked). The list of directories to back up files from will be retrieved from locations.txt. Backups will be incremental (only changed files will be backed up each time Backutil runs) and five previous backups will be retained. Download Use the link below to download Backutil. You’re free to run it for personal use - just please let me know if you encounter any bugs so I can work on fixing them in future realeases! Backutil is a learning/hobby project and some aspects of its code may not follow best practices. While you're welcome to use it, you do so at your own risk. Make sure you take a manual backup of your files before trying it out, and don't go relying on it to back up your production servers. Download Backutil v0.5136.6MB, ZIP The downloadable archive contains backutil.exe and an example config.ini file. Interested in the source code? The full Python script is available in the Backutil GitHub repository. Future development My determination to build a minimum viable product before the end of 2020 means that I have a backlog of bug fixes and new features to add during 2021. These include: Speed/efficiency improvements - As it stands, Backutil generates hashes and copies files via some fairly simple logic. As a next step I hope to implement a multithreading solution to process multiple files at once and reduce the time taken to perform each backup. Improved data storage - Backutil currently remembers what it has already backed up by recording file hashes in .back text files. I’d like to implement a more sophisticated system that stores this data in a more structured database, likely using SQLite. Inconsistencies and bug fixes - The more time you spend with a piece of code, the more flaws you find in it. So far my list includes inconsistencies in the --help output and improvements to the way the 7-Zip archive is generated, but I’m sure I’ll spot more along the way as I build other features. Remote backups - You’ll notice that some parts of Backutil use terminology associated with remote backups (for example, the Server section in the configuration file). This is because Backutil could originally be configured to use WinSCP to send backup files to a remote server. This has been removed for the initial release, but I hope to reinstate it in a future version. Graphical user interface (GUI) - I’ve played around with Python GUIs a couple of times before, but have never had a script worth implementing one for. Depending on time limitations, I might develop a GUI for Backutil to increase ease of use for less experienced users. Have you got more ideas for new Backutil features? Or have you found bugs that I haven’t? Please send me an email to let me know so I can add them to the development backlog. If you’re interested in the project, check back regularly for new releases. I’ll also announce any updates on my Twitter account, and may add some form of banner to my site’s homepage.</summary></entry><entry><title type="html">The best cyber security and technology books I read during 2020</title><link href="https://mattcasmith.net/2020/12/22/best-cyber-security-tech-books-2020" rel="alternate" type="text/html" title="The best cyber security and technology books I read during 2020" /><published>2020-12-22T00:00:00+00:00</published><updated>2020-12-22T00:00:00+00:00</updated><id>https://mattcasmith.net/2020/12/22/best-cyber-security-tech-books-2020%20-%20Copy</id><content type="html" xml:base="https://mattcasmith.net/2020/12/22/best-cyber-security-tech-books-2020">&lt;p&gt;One of the few upsides of the whole 2020 situation is that I’ve had a lot more time to read. Periods that I would usually have spent commuting, out with friends, or cramming in chores between getting home and going to bed became downtime that I could devote to good books. It was a small silver lining to a year that became something of an endurance test in staying at home and finding ways to amuse myself.&lt;/p&gt;

&lt;p&gt;I read more books in 2020 than I have since I was at college or university, so naturally, some of them were more notable, enjoyable, or informative than others. With that in mind, I thought I’d close off the year by sharing some of my favourite cyber security and tech titles. Also, it doesn’t look like my schedule will change any time soon, so if you have any suggestions for my 2021 reading list, please let me know!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/wp-content/uploads/2020/12/cybersecuritytechbooks2020.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;ghost-in-the-wires&quot;&gt;Ghost in the Wires&lt;/h3&gt;

&lt;p&gt;I’ll start with a book that should require little introduction for many of you, but had somehow passed me by until now. &lt;em&gt;Ghost in the Wires&lt;/em&gt; is the memoir of Kevin Mitnick, possibly the most famous hacker of all time. It tells the story of his time hacking various people and corporations for the sheer thrill of it and evading the American authorities attempting to track him down. This had been on my list for years, and I narrowly missed out on picking up a signed copy &lt;a href=&quot;https://mattcasmith.net/2019/08/26/im-back-def-con-inspired-hacking/&quot;&gt;at Black Hat last year&lt;/a&gt; (I actually passed Mitnick in a corridor shortly afterwards), but I finally got my hands on a copy in the summer.&lt;/p&gt;

&lt;p&gt;You’re unlikely to learn much from the book in a technical sense, partly because that’s not the point and partly because Mitnick’s tale takes place in the late 1980s and early 1990s, so many of the technologies and attacks mentioned are outdated. But &lt;em&gt;Ghost in the Wires&lt;/em&gt; is a real page-turner akin to many a fictional action thriller. It is rightly held as a classic of the genre, and should serve as a powerful reminder of the damage a skilled social engineer can cause to an unprepared organisation.&lt;/p&gt;

&lt;h3 id=&quot;chaos-monkeys&quot;&gt;Chaos Monkeys&lt;/h3&gt;

&lt;p&gt;Antonio Garcia Martinez’s humourous and often shocking account of his time on the Silicon Valley start-up scene is far less cyber-focused, but no less thrilling. It would be easy to compare this book to the HBO sitcom &lt;em&gt;Silicon Valley&lt;/em&gt;, but the difference is that everything in &lt;em&gt;Chaos Monkeys&lt;/em&gt; is true. It also includes rare insights into personal dealings with some of the most famous faces in tech.&lt;/p&gt;

&lt;p&gt;Martinez covers his journey from Goldman Sachs to his own start-up and eventually to Facebook, with many intriguing details along the way. Despite his stories of some of the more scandalous behaviour in the California bubble, it’s nearly impossible to read this without becoming inspired by the big dreams and hard work of tech founders, and &lt;a href=&quot;https://mattcasmith.net/2020/06/30/new-website-new-philosophy/&quot;&gt;it was even the indirect inspiration for the latest iteration of this blog&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;countdown-to-zero-day&quot;&gt;Countdown to Zero Day&lt;/h3&gt;

&lt;p&gt;As a former cyber security journalist, I know just how hard it is to combine ground-level technical detail, organisational and industry fallout, and developments in the global geopolitical landscape into a compelling story. That’s why what Kim Zetter has done here is an even bigger triumph. She tells the story of Stuxnet in a way that will satisfy industry veterans and casual observers alike, framing the campaign with detail that provides valuable context for subsequent events such as the NotPetya incident.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Countdown to Zero Day&lt;/em&gt; does a fantastic job of providing an account of the Stuxnet campaign at all levels, from the corridors of the US government and Department of Defense to the Iranian nuclear facilities it targeted and the researchers at companies like Symantec racing to decipher how the malware worked. While it doesn’t touch the low-level technical details (understandably - that would fill a book all to itself), Zetter’s account breaks down the core functionality of Stuxnet - much of which also applies more broadly to other malware variants - in a way that both techies and non-techies will understand.&lt;/p&gt;

&lt;h3 id=&quot;code-the-hidden-language-of-computer-hardware-and-software&quot;&gt;Code: The Hidden Language of Computer Hardware and Software&lt;/h3&gt;

&lt;p&gt;Have you ever wondered how computers actually use all those ones and zeroes to allow us to send emails, edit Word documents, and write new programs in C++? Charles Petzold’s book covers more ground than just about any I’ve ever read, beginning with relatively simple systems like Morse code and, over the course of fewer than 400 pages, building a theoretical telegraph system, processor, RAM, and eventually a computer akin to those we use every day. It really is quite staggering to think about.&lt;/p&gt;

&lt;p&gt;While the detail presented in &lt;em&gt;Code&lt;/em&gt; isn’t something most of us will consider in the course of our daily lives, it does help to dispel the “magic box” effect surrounding PCs and smartphones. For my colleagues in the cyber security industry, it also provides a great overview of the relationship between binary and machine language, assembly, and high- and low-level programming languages, as well as where data is stored in CPU registers and RAM when code is run - fundamentals for malware analysts and bug hunters.&lt;/p&gt;

&lt;h3 id=&quot;practical-packet-analysis&quot;&gt;Practical Packet Analysis&lt;/h3&gt;

&lt;p&gt;No Starch Press is always a good bet for solid technology and cyber security books, and &lt;a href=&quot;https://nostarch.com/&quot; target=&quot;_blank&quot;&gt;the publisher’s website&lt;/a&gt; often serves as my starting point when I’m looking for something technical to read. I read a couple of their titles this year, but the highlight has to be &lt;em&gt;Practical Packet Analysis&lt;/em&gt;, which I worked through during some leave in the summer. At face value, the book is billed as a guide to using Wireshark to solve network problems, but it actually covers a lot more than that.&lt;/p&gt;

&lt;p&gt;For anybody new to networking, I think the opening chapters provide about the clearest explanation of the OSI model, TCP/IP, and common protocols that you’ll find anywhere. This is followed by an extensive rundown of Wireshark’s interface and features, including a guide on where and how to capture network traffic, as well as a series of scenarios where packet analysis helps to diagnose network problems, complete with downloadable PCAP files to follow along and get some practice in.&lt;/p&gt;</content><author><name>mattcasmith</name></author><summary type="html">One of the few upsides of the whole 2020 situation is that I’ve had a lot more time to read. Periods that I would usually have spent commuting, out with friends, or cramming in chores between getting home and going to bed became downtime that I could devote to good books. It was a small silver lining to a year that became something of an endurance test in staying at home and finding ways to amuse myself. I read more books in 2020 than I have since I was at college or university, so naturally, some of them were more notable, enjoyable, or informative than others. With that in mind, I thought I’d close off the year by sharing some of my favourite cyber security and tech titles. Also, it doesn’t look like my schedule will change any time soon, so if you have any suggestions for my 2021 reading list, please let me know! Ghost in the Wires I’ll start with a book that should require little introduction for many of you, but had somehow passed me by until now. Ghost in the Wires is the memoir of Kevin Mitnick, possibly the most famous hacker of all time. It tells the story of his time hacking various people and corporations for the sheer thrill of it and evading the American authorities attempting to track him down. This had been on my list for years, and I narrowly missed out on picking up a signed copy at Black Hat last year (I actually passed Mitnick in a corridor shortly afterwards), but I finally got my hands on a copy in the summer. You’re unlikely to learn much from the book in a technical sense, partly because that’s not the point and partly because Mitnick’s tale takes place in the late 1980s and early 1990s, so many of the technologies and attacks mentioned are outdated. But Ghost in the Wires is a real page-turner akin to many a fictional action thriller. It is rightly held as a classic of the genre, and should serve as a powerful reminder of the damage a skilled social engineer can cause to an unprepared organisation. Chaos Monkeys Antonio Garcia Martinez’s humourous and often shocking account of his time on the Silicon Valley start-up scene is far less cyber-focused, but no less thrilling. It would be easy to compare this book to the HBO sitcom Silicon Valley, but the difference is that everything in Chaos Monkeys is true. It also includes rare insights into personal dealings with some of the most famous faces in tech. Martinez covers his journey from Goldman Sachs to his own start-up and eventually to Facebook, with many intriguing details along the way. Despite his stories of some of the more scandalous behaviour in the California bubble, it’s nearly impossible to read this without becoming inspired by the big dreams and hard work of tech founders, and it was even the indirect inspiration for the latest iteration of this blog. Countdown to Zero Day As a former cyber security journalist, I know just how hard it is to combine ground-level technical detail, organisational and industry fallout, and developments in the global geopolitical landscape into a compelling story. That’s why what Kim Zetter has done here is an even bigger triumph. She tells the story of Stuxnet in a way that will satisfy industry veterans and casual observers alike, framing the campaign with detail that provides valuable context for subsequent events such as the NotPetya incident. Countdown to Zero Day does a fantastic job of providing an account of the Stuxnet campaign at all levels, from the corridors of the US government and Department of Defense to the Iranian nuclear facilities it targeted and the researchers at companies like Symantec racing to decipher how the malware worked. While it doesn’t touch the low-level technical details (understandably - that would fill a book all to itself), Zetter’s account breaks down the core functionality of Stuxnet - much of which also applies more broadly to other malware variants - in a way that both techies and non-techies will understand. Code: The Hidden Language of Computer Hardware and Software Have you ever wondered how computers actually use all those ones and zeroes to allow us to send emails, edit Word documents, and write new programs in C++? Charles Petzold’s book covers more ground than just about any I’ve ever read, beginning with relatively simple systems like Morse code and, over the course of fewer than 400 pages, building a theoretical telegraph system, processor, RAM, and eventually a computer akin to those we use every day. It really is quite staggering to think about. While the detail presented in Code isn’t something most of us will consider in the course of our daily lives, it does help to dispel the “magic box” effect surrounding PCs and smartphones. For my colleagues in the cyber security industry, it also provides a great overview of the relationship between binary and machine language, assembly, and high- and low-level programming languages, as well as where data is stored in CPU registers and RAM when code is run - fundamentals for malware analysts and bug hunters. Practical Packet Analysis No Starch Press is always a good bet for solid technology and cyber security books, and the publisher’s website often serves as my starting point when I’m looking for something technical to read. I read a couple of their titles this year, but the highlight has to be Practical Packet Analysis, which I worked through during some leave in the summer. At face value, the book is billed as a guide to using Wireshark to solve network problems, but it actually covers a lot more than that. For anybody new to networking, I think the opening chapters provide about the clearest explanation of the OSI model, TCP/IP, and common protocols that you’ll find anywhere. This is followed by an extensive rundown of Wireshark’s interface and features, including a guide on where and how to capture network traffic, as well as a series of scenarios where packet analysis helps to diagnose network problems, complete with downloadable PCAP files to follow along and get some practice in.</summary></entry><entry><title type="html">AWS: Deploying and connecting to a SQL database in the cloud</title><link href="https://mattcasmith.net/2020/11/15/aws-deploy-connect-sql-database-cloud" rel="alternate" type="text/html" title="AWS&amp;#58; Deploying and connecting to a SQL database in the cloud" /><published>2020-11-20T00:00:00+00:00</published><updated>2020-11-20T00:00:00+00:00</updated><id>https://mattcasmith.net/2020/11/15/aws-deploy-connecting-sql-database-cloud%20-%20Copy</id><content type="html" xml:base="https://mattcasmith.net/2020/11/15/aws-deploy-connect-sql-database-cloud">&lt;p&gt;My first Amazon Web Services (AWS) basics post covered the process of &lt;a href=&quot;https://mattcasmith.net/2020/11/15/aws-deploying-virtual-network-server-cloud&quot;&gt;setting up a Virtual Private Cloud (VPC) and a Windows Server 2019 EC2 instance&lt;/a&gt;. This time we’re going to build on this simple setup by deploying a Amazon Aurora SQL database and ensuring we can access it from our server.&lt;/p&gt;

&lt;h3 id=&quot;aws-basics-series&quot;&gt;AWS basics series&lt;/h3&gt;

&lt;p&gt;1. &lt;a href=&quot;https://mattcasmith.net/2020/11/15/aws-deploying-virtual-network-server-cloud&quot;&gt;Deploying a virtual network and server&lt;/a&gt;&lt;br /&gt;
2. Deploying and connecting to a SQL database&lt;/p&gt;

&lt;h3 id=&quot;databases-in-aws&quot;&gt;Databases in AWS&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/products/databases/&quot; target=&quot;_blank&quot;&gt;Databases in AWS&lt;/a&gt; generally come in three different flavours, which are all designed for different use cases, data volumes, and availability requirements. These are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Relational Database Service (RDS)&lt;/strong&gt; - Relational databases are typical, structured, table-based databases. AWS gives you the option to run MySQL, Oracle SQL, and Microsoft SQL Server among other established names, but also offers its own database engine called &lt;a href=&quot;https://aws.amazon.com/rds/aurora/&quot; target=&quot;_blank&quot;&gt;Amazon Aurora&lt;/a&gt;, which is optimised with a few extra features designed for the cloud.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;DynamoDB&lt;/strong&gt; - DynamoDB is a NoSQL database consisting of key-value pairs for less structured data. This can be a good option if the speed of queries is the most important factor.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Redshift&lt;/strong&gt; - Redshift is the AWS service for data warehouses. This is the best solution if you have petabytes of data to store, and is optimised for handling these large datasets.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/products/databases/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;\wp-content\uploads\2020\11\aws-sql-dbs.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To keep things simple, we’ll assume our data will fit nicely in an RDS database that needs to be accessed from the Windows Server 2019 EC2 instance we deployed in the last post. Deploying an RDS database will take three steps: creating the database, ensuring our server has the correct access permissions, and connecting to the database to use it. Let’s get started with the setup.&lt;/p&gt;

&lt;h3 id=&quot;deploying-an-aws-rds-database&quot;&gt;Deploying an AWS RDS database&lt;/h3&gt;

&lt;p&gt;Navigate to the RDS dashboard and look for the Create Database section, where there is also a Create Database button. Clicking this will take you to a form where you can choose the configuration of your new database, from the engine to which VPC it sits in. Click the Standard Create option to continue.&lt;/p&gt;

&lt;p&gt;Now let’s select an engine for our SQL database. You may instinctively reach for the familiar names like MySQL and Microsoft SQL Server, but I’m going to use Amazon Aurora (selecting the edition with MySQL compatibility). This is Amazon’s own database engine, which is optimised for use in the AWS cloud and can support higher throughput, auto-scaling, and replication across availability zones.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;\wp-content\uploads\2020\11\aws-sql-engine.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We’ll choose Provisioned capacity, which means we manage the server instance the database sits on, and select the Dev/Test template to avoid any extra charges for the high availability and resilience aspects of the Production template. Next we can create a username and password for the master user - make a note of these details as we’ll need them to access the database later on.&lt;/p&gt;

&lt;p&gt;Scroll down and you have the opportunity to choose the VPC (basically the network) your database should sit in. We’ll choose the &lt;code&gt;server-deployment&lt;/code&gt; VPC we configured during the first blog post. This will make it easier to reach the database from the server and will do for our simple example, but it is not recommended to deploy production databases in VPCs with internet access - it would be best to tuck them away in their own VPC and configure rules for access from another.&lt;/p&gt;

&lt;p&gt;Let’s also create a new Security Group to allow access to the database. We’ll call it &lt;code&gt;database-access&lt;/code&gt; and configure it a bit later. Click Create Database and you’ll be taken back to the Databases Dashboard, where you’ll be able to see your new Aurora MySQL database is now being created.&lt;/p&gt;

&lt;h3 id=&quot;granting-access-to-the-ec2-server-instance&quot;&gt;Granting access to the EC2 server instance&lt;/h3&gt;

&lt;p&gt;But if we were to try to connect from our EC2 server to the database now, our connection would fail. Why? Because we haven’t configured the Security Group to allow the connection. We can rectify this by navigating to the VPC Dashboard and clicking on Security Groups. From there we can add a rule that allows access on port 3306 from the subnet our server sits in (&lt;code&gt;10.0.0.0/24&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;\wp-content\uploads\2020\11\aws-sql-security-group.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;That’s it - we’ve deployed a SQL database and given our server access to it. The next step is to log in and manipulate some data, just to prove that the database and connection both work.&lt;/p&gt;

&lt;h3 id=&quot;connecting-to-the-aws-rds-database&quot;&gt;Connecting to the AWS RDS database&lt;/h3&gt;

&lt;p&gt;If we RDP to our server, we can now connect to our SQL database - but first, you’ll need to download a client. I used Oracle’s &lt;a href=&quot;https://dev.mysql.com/downloads/&quot; target=&quot;_blank&quot;&gt;MySQL Shell&lt;/a&gt;, with which you can establish a connection with this command:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;\&lt;span class=&quot;n&quot;&gt;mysqlsh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exe&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;database&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endpoint&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3306&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;username&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;After entering our password, we are connected to the database and can interact with its contents using standard SQL commands to add, remove, merge, and filter data. Looks like it’s good to go! If you need any tips on how to manipulate data with SQL, see my previous posts on &lt;a href=&quot;https://mattcasmith.net/2018/10/12/basic-sql-queries-select-from-where-operators/&quot;&gt;basic SQL commands&lt;/a&gt;, &lt;a href=&quot;https://mattcasmith.net/2018/12/21/sql-joins-inner-left-right-outer/&quot;&gt;SQL JOINs&lt;/a&gt;, and &lt;a href=&quot;https://mattcasmith.net/2019/02/01/sql-alter-table-add-modify-drop-columns/&quot;&gt;SQL TABLE commands&lt;/a&gt;, which should help you to get started.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;\wp-content\uploads\2020\11\aws-sql-mysql.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Again, make sure you go back to the EC2 and RDS Dashboards when you’re finished and stop your EC2 instance and RDS database. This will help you to avoid any unexpected AWS charges.&lt;/p&gt;

&lt;p&gt;So now we have &lt;a href=&quot;https://mattcasmith.net/2020/11/15/aws-deploying-virtual-network-server-cloud&quot;&gt;a VPC and a Windows Server 2019 EC2 instance&lt;/a&gt;, and have deployed a simple RDS Aurora database that we can access from it. In my next and final AWS basics post, I’ll run through how to set up an S3 bucket to store some files in the cloud (and avoid sharing them with everyone).&lt;/p&gt;</content><author><name>mattcasmith</name></author><summary type="html">My first Amazon Web Services (AWS) basics post covered the process of setting up a Virtual Private Cloud (VPC) and a Windows Server 2019 EC2 instance. This time we’re going to build on this simple setup by deploying a Amazon Aurora SQL database and ensuring we can access it from our server. AWS basics series 1. Deploying a virtual network and server 2. Deploying and connecting to a SQL database Databases in AWS Databases in AWS generally come in three different flavours, which are all designed for different use cases, data volumes, and availability requirements. These are: Relational Database Service (RDS) - Relational databases are typical, structured, table-based databases. AWS gives you the option to run MySQL, Oracle SQL, and Microsoft SQL Server among other established names, but also offers its own database engine called Amazon Aurora, which is optimised with a few extra features designed for the cloud. DynamoDB - DynamoDB is a NoSQL database consisting of key-value pairs for less structured data. This can be a good option if the speed of queries is the most important factor. Redshift - Redshift is the AWS service for data warehouses. This is the best solution if you have petabytes of data to store, and is optimised for handling these large datasets. To keep things simple, we’ll assume our data will fit nicely in an RDS database that needs to be accessed from the Windows Server 2019 EC2 instance we deployed in the last post. Deploying an RDS database will take three steps: creating the database, ensuring our server has the correct access permissions, and connecting to the database to use it. Let’s get started with the setup. Deploying an AWS RDS database Navigate to the RDS dashboard and look for the Create Database section, where there is also a Create Database button. Clicking this will take you to a form where you can choose the configuration of your new database, from the engine to which VPC it sits in. Click the Standard Create option to continue. Now let’s select an engine for our SQL database. You may instinctively reach for the familiar names like MySQL and Microsoft SQL Server, but I’m going to use Amazon Aurora (selecting the edition with MySQL compatibility). This is Amazon’s own database engine, which is optimised for use in the AWS cloud and can support higher throughput, auto-scaling, and replication across availability zones. We’ll choose Provisioned capacity, which means we manage the server instance the database sits on, and select the Dev/Test template to avoid any extra charges for the high availability and resilience aspects of the Production template. Next we can create a username and password for the master user - make a note of these details as we’ll need them to access the database later on. Scroll down and you have the opportunity to choose the VPC (basically the network) your database should sit in. We’ll choose the server-deployment VPC we configured during the first blog post. This will make it easier to reach the database from the server and will do for our simple example, but it is not recommended to deploy production databases in VPCs with internet access - it would be best to tuck them away in their own VPC and configure rules for access from another. Let’s also create a new Security Group to allow access to the database. We’ll call it database-access and configure it a bit later. Click Create Database and you’ll be taken back to the Databases Dashboard, where you’ll be able to see your new Aurora MySQL database is now being created. Granting access to the EC2 server instance But if we were to try to connect from our EC2 server to the database now, our connection would fail. Why? Because we haven’t configured the Security Group to allow the connection. We can rectify this by navigating to the VPC Dashboard and clicking on Security Groups. From there we can add a rule that allows access on port 3306 from the subnet our server sits in (10.0.0.0/24). That’s it - we’ve deployed a SQL database and given our server access to it. The next step is to log in and manipulate some data, just to prove that the database and connection both work. Connecting to the AWS RDS database If we RDP to our server, we can now connect to our SQL database - but first, you’ll need to download a client. I used Oracle’s MySQL Shell, with which you can establish a connection with this command: .\mysqlsh.exe -h &amp;lt;insert database endpoint address&amp;gt; -P 3306 -u &amp;lt;username&amp;gt; -p After entering our password, we are connected to the database and can interact with its contents using standard SQL commands to add, remove, merge, and filter data. Looks like it’s good to go! If you need any tips on how to manipulate data with SQL, see my previous posts on basic SQL commands, SQL JOINs, and SQL TABLE commands, which should help you to get started. Again, make sure you go back to the EC2 and RDS Dashboards when you’re finished and stop your EC2 instance and RDS database. This will help you to avoid any unexpected AWS charges. So now we have a VPC and a Windows Server 2019 EC2 instance, and have deployed a simple RDS Aurora database that we can access from it. In my next and final AWS basics post, I’ll run through how to set up an S3 bucket to store some files in the cloud (and avoid sharing them with everyone).</summary></entry><entry><title type="html">AWS: Deploying a virtual network and server in the cloud</title><link href="https://mattcasmith.net/2020/11/15/aws-deploying-virtual-network-server-cloud" rel="alternate" type="text/html" title="AWS&amp;#58; Deploying a virtual network and server in the cloud" /><published>2020-11-15T00:00:00+00:00</published><updated>2020-11-15T00:00:00+00:00</updated><id>https://mattcasmith.net/2020/11/15/aws-deploying-virtual-server-cloud</id><content type="html" xml:base="https://mattcasmith.net/2020/11/15/aws-deploying-virtual-network-server-cloud">&lt;p&gt;Having worked on serveral projects involving Amazon Web Services (AWS) recently, but always at arm’s length, I decided to get a bit more hands-on. At worst this would give me a more practical grounding in managing cloud instances, and at best it would give me a useful resource for future &lt;a href=&quot;https://mattcasmith.net/category/programming.html&quot;&gt;coding projects&lt;/a&gt;. So I got to work and set up an account to play around with some of Amazon’s services.&lt;/p&gt;

&lt;p&gt;The nice thing about the platform is the &lt;a href=&quot;https://aws.amazon.com/free/&quot; target=&quot;_blank&quot;&gt;AWS Free Tier&lt;/a&gt; offering. This is automatically applied to all new users’ accounts and gives free access to many services, at least for the first 12 months. The ins and outs of what’s included and what’s not are a bit complex, but the headline is that unless you deploy anything particularly computationally expensive, you’re not likely to incur any costs within your first year.&lt;/p&gt;

&lt;p&gt;To help my learnings sink in, I’m going to write a few posts detailing how to perform basic tasks, beginning with setting up an EC2 instance (more on what that is later). But before you get started, make sure you have the basics covered - namely registering for an account, choosing a strong, unique password, and activating two-factor authentication, as you should for all your accounts. Once you’ve completed all of that, log in to the AWS Management Console to get started.&lt;/p&gt;

&lt;h3 id=&quot;aws-basics-series&quot;&gt;AWS basics series&lt;/h3&gt;

&lt;p&gt;1. Deploying a virtual network and server&lt;br /&gt;
2. &lt;a href=&quot;https://mattcasmith.net/2020/11/15/aws-deploy-connect-sql-database-cloud&quot;&gt;Deploying and connecting to a SQL database&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;configuring-a-virtual-private-cloud-vpc&quot;&gt;Configuring a Virtual Private Cloud (VPC)&lt;/h3&gt;

&lt;p&gt;Virtual Private Clouds (VPCs) are Amazon’s way of organising your cloud resources. They are essentially internal IP address ranges where servers and other entities can be deployed, with settings for various levels of internal and external communication via firewall-esque rules and the deployment of subnets. Before we deploy our server, we need to create a VPC for it to sit in.&lt;/p&gt;

&lt;p&gt;AWS provides a VPC by default, but for the sake of experience I’ll set up a new VPC for our server by clicking Create VPC, giving it the name &lt;code&gt;server-deployment&lt;/code&gt;, and assigning the internal IP address range &lt;code&gt;10.0.0.0/24&lt;/code&gt;. It’s as simple as that - click Create VPC and AWS will instantly deploy it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;\wp-content\uploads\2020\11\aws-server-vpc.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Servers must sit on subnets within VPCs, so head back to the VPC Dashboard and click Subnets, then Create Subnet. I’ll call mine &lt;code&gt;subnet-a&lt;/code&gt;, put it in the &lt;code&gt;server-deployment&lt;/code&gt; VPC, and assign the IP address range &lt;code&gt;10.0.0.0/24&lt;/code&gt; to the subnet. This will assign the whole VPC IP address range to a single subnet, but that’s not an issue for this example as we’ll only be deploying a single server.&lt;/p&gt;

&lt;p&gt;Now we have a VPC and a subnet, we need to create a path from the subnet to the internet so we can access our server. Click on Internet Gateways in the VPC Dashboard sidebar, create a new Internet Gateway (mine is called &lt;code&gt;server-internet-gateway&lt;/code&gt;) and attach it to your VPC. Then click Route Tables in the sidebar, select the Route Table for your VPC, click on the Routes tab, and select Edit Routes. A route that sends all traffic with the destination &lt;code&gt;0.0.0.0/0&lt;/code&gt; to the new Internet Gateway will allow the server to reach the internet, which is not always desirable but is necessary for direct access in this case.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;\wp-content\uploads\2020\11\aws-server-vpc-routes.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;setting-up-an-elastic-compute-cloud-ec2-instance&quot;&gt;Setting up an Elastic Compute Cloud (EC2) instance&lt;/h3&gt;

&lt;p&gt;Now let’s create a Windows server within our VPC, and configure it in such a way that we can access it from outside of AWS. Servers within AWS are called Elastic Compute Cloud (EC2) instances, so to deploy one we’ll need to navigate to the EC2 Dashboard and click Launch Instance.&lt;/p&gt;

&lt;p&gt;Here we’ll be presented with a list of what AWS calls Amazon Machine Images (AMIs). Each AMI is essentially the equivalent of a gold image in an on-premise environment. We can select from a variety of images (if you’re using AWS Free Tier, those that are included free of charge are indicated), but for the purposes of this example I’ll select the Microsoft Windows Server 2019 Base AMI.&lt;/p&gt;

&lt;p&gt;Next we’re asked to choose an instance type. This screen essentially shows a huge list of options for the number of CPUs, amount of RAM, and network performance that our server should have. We only have one option within AWS Free Tier - the &lt;code&gt;t2.micro&lt;/code&gt; instance type - so we’ll go with that.&lt;/p&gt;

&lt;p&gt;Then we’re given the opportunity to choose some settings for our instance. The important thing here is that the Network setting is set to &lt;code&gt;server-deployment&lt;/code&gt; - the VPC we created in the last section. We also need to choose a subnet - that will be &lt;code&gt;subnet-a&lt;/code&gt; (&lt;code&gt;10.0.0.0/24&lt;/code&gt;) in my case. Be sure to enable public IP assignment if you need to be able to access the server from the internet. We can also set up network interfaces and assign IP addresses here, but I’ll stick with the default and let AWS handle it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;\wp-content\uploads\2020\11\aws-server-ec2-instance-details.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The next screen allocates storage to the server in the form of an Elastic Block Store (EBS), which essentially functions as a hard drive volume. Again, our options under AWS Free Tier are limited to a 30GB General Purpose SSD. It’s also a good idea to encrypt our volume for an additional layer of protection.&lt;/p&gt;

&lt;p&gt;Next up are tags, which allow us to categorise assets to help to manage costs, billing, and so on. As I’m deploying a lone server and will soon be terminating it, I won’t add any tags.&lt;/p&gt;

&lt;p&gt;The next step is crucially important. Security Groups essentially function as firewalls for EC2 instances. As any good firewall configuration should, they default to &lt;code&gt;deny all&lt;/code&gt;. We’ll need to use Remote Desktop Protocol (RDP) on TCP port 3389 to access our server, so I’ll create a new Security Group called &lt;code&gt;rdp-admin&lt;/code&gt; and allow incoming connections on that port - but we don’t want this to be exposed to the whole internet, so I’ll restrict access to my IP address (which is handily a preset AWS option).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;\wp-content\uploads\2020\11\aws-server-ec2-security-group.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Click Review and Launch and you’ll have one last chance to check everything is in order before pulling the trigger and deploying your server. When you click Launch, you’ll be given the opportunity to create a new key pair, which you’ll use to decrypt the password to access the server. Name your key pair (I’ll call mine &lt;code&gt;win-server-admin&lt;/code&gt;, download the &lt;code&gt;.pem&lt;/code&gt; private key file, and keep it somewhere safe.&lt;/p&gt;

&lt;p&gt;Congratulations - you’ve deployed Windows Server 2019 in the AWS cloud!&lt;/p&gt;

&lt;h3 id=&quot;connecting-to-the-windows-server&quot;&gt;Connecting to the Windows server&lt;/h3&gt;

&lt;p&gt;If you return to the EC2 dashboard and click on Instances, you’ll now be able to see your server running in AWS. That’s great - but it’s just a number in a management dashboard. How do we actually use it?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;\wp-content\uploads\2020\11\aws-server-ec2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As I previously mentioned, the answer lies with RDP - a protocol that allows us to access another Windows computer remotely and interact with it as though we’re sat in front of it using the mouse and keyboard. To prepare to connect, open the Remote Desktop Connection app in your Windows PC (click Start and type &lt;code&gt;RDP&lt;/code&gt; to find it) and enter your EC2 instance’s public IP address in the Computer field.&lt;/p&gt;

&lt;p&gt;Back on your EC2 instance’s page on the AWS dashboard, click Connect and then switch to the RDP Client tab. Then select Get Password and upload the &lt;code&gt;.pem&lt;/code&gt; private key file you downloaded earlier to decrypt the password. When you click Connect to start the session, the default username is &lt;code&gt;Administrator&lt;/code&gt; and you’ll be able to copy and paste the password to authenticate and connect to the server.&lt;/p&gt;

&lt;p&gt;Once you’re finished and the RDP client has done its thing, you should see your Windows Server 2019 desktop. You can now use your cloud server as though it was a physical computer on your desk.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;\wp-content\uploads\2020\11\aws-server-ec2-rdp.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can now use your virtual server for whatever your heart desires - just make sure you remember to stop it on the EC2 Dashboard whenever you’re finished using it so you don’t incur any extra costs.&lt;/p&gt;

&lt;p&gt;This was, of course, a very simple deployment. Setting up an enterprise-scale AWS environment would require much more planning and architecture design to ensure efficiency and security. However, a simple VPC and server is a good starting point, and this is something I’ll build on in a few more posts that will cover the deployment of commonly used AWS services like databases and S3 buckets.&lt;/p&gt;</content><author><name>mattcasmith</name></author><summary type="html">Having worked on serveral projects involving Amazon Web Services (AWS) recently, but always at arm’s length, I decided to get a bit more hands-on. At worst this would give me a more practical grounding in managing cloud instances, and at best it would give me a useful resource for future coding projects. So I got to work and set up an account to play around with some of Amazon’s services. The nice thing about the platform is the AWS Free Tier offering. This is automatically applied to all new users’ accounts and gives free access to many services, at least for the first 12 months. The ins and outs of what’s included and what’s not are a bit complex, but the headline is that unless you deploy anything particularly computationally expensive, you’re not likely to incur any costs within your first year. To help my learnings sink in, I’m going to write a few posts detailing how to perform basic tasks, beginning with setting up an EC2 instance (more on what that is later). But before you get started, make sure you have the basics covered - namely registering for an account, choosing a strong, unique password, and activating two-factor authentication, as you should for all your accounts. Once you’ve completed all of that, log in to the AWS Management Console to get started. AWS basics series 1. Deploying a virtual network and server 2. Deploying and connecting to a SQL database Configuring a Virtual Private Cloud (VPC) Virtual Private Clouds (VPCs) are Amazon’s way of organising your cloud resources. They are essentially internal IP address ranges where servers and other entities can be deployed, with settings for various levels of internal and external communication via firewall-esque rules and the deployment of subnets. Before we deploy our server, we need to create a VPC for it to sit in. AWS provides a VPC by default, but for the sake of experience I’ll set up a new VPC for our server by clicking Create VPC, giving it the name server-deployment, and assigning the internal IP address range 10.0.0.0/24. It’s as simple as that - click Create VPC and AWS will instantly deploy it. Servers must sit on subnets within VPCs, so head back to the VPC Dashboard and click Subnets, then Create Subnet. I’ll call mine subnet-a, put it in the server-deployment VPC, and assign the IP address range 10.0.0.0/24 to the subnet. This will assign the whole VPC IP address range to a single subnet, but that’s not an issue for this example as we’ll only be deploying a single server. Now we have a VPC and a subnet, we need to create a path from the subnet to the internet so we can access our server. Click on Internet Gateways in the VPC Dashboard sidebar, create a new Internet Gateway (mine is called server-internet-gateway) and attach it to your VPC. Then click Route Tables in the sidebar, select the Route Table for your VPC, click on the Routes tab, and select Edit Routes. A route that sends all traffic with the destination 0.0.0.0/0 to the new Internet Gateway will allow the server to reach the internet, which is not always desirable but is necessary for direct access in this case. Setting up an Elastic Compute Cloud (EC2) instance Now let’s create a Windows server within our VPC, and configure it in such a way that we can access it from outside of AWS. Servers within AWS are called Elastic Compute Cloud (EC2) instances, so to deploy one we’ll need to navigate to the EC2 Dashboard and click Launch Instance. Here we’ll be presented with a list of what AWS calls Amazon Machine Images (AMIs). Each AMI is essentially the equivalent of a gold image in an on-premise environment. We can select from a variety of images (if you’re using AWS Free Tier, those that are included free of charge are indicated), but for the purposes of this example I’ll select the Microsoft Windows Server 2019 Base AMI. Next we’re asked to choose an instance type. This screen essentially shows a huge list of options for the number of CPUs, amount of RAM, and network performance that our server should have. We only have one option within AWS Free Tier - the t2.micro instance type - so we’ll go with that. Then we’re given the opportunity to choose some settings for our instance. The important thing here is that the Network setting is set to server-deployment - the VPC we created in the last section. We also need to choose a subnet - that will be subnet-a (10.0.0.0/24) in my case. Be sure to enable public IP assignment if you need to be able to access the server from the internet. We can also set up network interfaces and assign IP addresses here, but I’ll stick with the default and let AWS handle it. The next screen allocates storage to the server in the form of an Elastic Block Store (EBS), which essentially functions as a hard drive volume. Again, our options under AWS Free Tier are limited to a 30GB General Purpose SSD. It’s also a good idea to encrypt our volume for an additional layer of protection. Next up are tags, which allow us to categorise assets to help to manage costs, billing, and so on. As I’m deploying a lone server and will soon be terminating it, I won’t add any tags. The next step is crucially important. Security Groups essentially function as firewalls for EC2 instances. As any good firewall configuration should, they default to deny all. We’ll need to use Remote Desktop Protocol (RDP) on TCP port 3389 to access our server, so I’ll create a new Security Group called rdp-admin and allow incoming connections on that port - but we don’t want this to be exposed to the whole internet, so I’ll restrict access to my IP address (which is handily a preset AWS option). Click Review and Launch and you’ll have one last chance to check everything is in order before pulling the trigger and deploying your server. When you click Launch, you’ll be given the opportunity to create a new key pair, which you’ll use to decrypt the password to access the server. Name your key pair (I’ll call mine win-server-admin, download the .pem private key file, and keep it somewhere safe. Congratulations - you’ve deployed Windows Server 2019 in the AWS cloud! Connecting to the Windows server If you return to the EC2 dashboard and click on Instances, you’ll now be able to see your server running in AWS. That’s great - but it’s just a number in a management dashboard. How do we actually use it? As I previously mentioned, the answer lies with RDP - a protocol that allows us to access another Windows computer remotely and interact with it as though we’re sat in front of it using the mouse and keyboard. To prepare to connect, open the Remote Desktop Connection app in your Windows PC (click Start and type RDP to find it) and enter your EC2 instance’s public IP address in the Computer field. Back on your EC2 instance’s page on the AWS dashboard, click Connect and then switch to the RDP Client tab. Then select Get Password and upload the .pem private key file you downloaded earlier to decrypt the password. When you click Connect to start the session, the default username is Administrator and you’ll be able to copy and paste the password to authenticate and connect to the server. Once you’re finished and the RDP client has done its thing, you should see your Windows Server 2019 desktop. You can now use your cloud server as though it was a physical computer on your desk. You can now use your virtual server for whatever your heart desires - just make sure you remember to stop it on the EC2 Dashboard whenever you’re finished using it so you don’t incur any extra costs. This was, of course, a very simple deployment. Setting up an enterprise-scale AWS environment would require much more planning and architecture design to ensure efficiency and security. However, a simple VPC and server is a good starting point, and this is something I’ll build on in a few more posts that will cover the deployment of commonly used AWS services like databases and S3 buckets.</summary></entry><entry><title type="html">Cracking a password-protected ZIP file with fcrackzip</title><link href="https://mattcasmith.net/2020/09/12/cracking-password-protected-zip-file-fcrackzip" rel="alternate" type="text/html" title="Cracking a password-protected ZIP file with fcrackzip" /><published>2020-09-12T01:00:00+01:00</published><updated>2020-09-12T01:00:00+01:00</updated><id>https://mattcasmith.net/2020/09/12/cracking-password-protected-zip-fcrackzip%20-%20Copy%20-%20Copy</id><content type="html" xml:base="https://mattcasmith.net/2020/09/12/cracking-password-protected-zip-file-fcrackzip">&lt;p&gt;I recently took part in a DFIR capture the flag with some colleagues. Participants were provided with a system disk image and asked to mount it and complete a number of challenges to discover various flags hidden within the data. Exercises like this are always both a lot of fun and a good way to share knowledge and learn - after all, there’s no better time to pick up new techniques than in the heat of competition.&lt;/p&gt;

&lt;p&gt;I got most of the answers and finished joint second. One of the questions I didn’t have time for, which I deprioritised as I would have needed to look up the methodology, involved discovering the password to an encrypted ZIP file to access the flag inside. To make sure I can complete similar challenges in future CTFs (or live scenarios), I decided to do some digging, crack a ZIP, and document my method.&lt;/p&gt;

&lt;h3 id=&quot;creating-a-password-protected-zip-archive&quot;&gt;Creating a password-protected ZIP archive&lt;/h3&gt;

&lt;p&gt;To emulate the conditions of the CTF, I needed to create a ZIP archive containing a text file with the would-be flag. Creating the text file is a simple as using &lt;code&gt;echo&lt;/code&gt; to write some content to a file.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;This is a secret file.&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;secretfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;txt&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We can then use 7-Zip to create a password-protected ZIP archive. The &lt;code&gt;a&lt;/code&gt; option tells 7-Zip that we’re adding files to an archive. We then specify the name of the archive and the file we wish to add. Finally, the &lt;code&gt;-p&lt;/code&gt; option allows us to add a password - in this case, the very secure &lt;code&gt;thisisapassword&lt;/code&gt;. Also note that the lack of a space isn’t a typo - that’s just the way 7-Zip wants the information to be provided.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;archive&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;secretfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;txt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pthisisapassword&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now let’s check that the password was properly applied to the archive using the GUI. We can see that if we open &lt;code&gt;archive.zip&lt;/code&gt;, we can see the file listing inside, but if we double-click to open any of the files we receive a prompt and cannot see the contents without entering the correct password.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/wp-content/uploads/2020/09/fcrackzip_1.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;cracking-the-password-protected-zip-archive-with-fcrackzip&quot;&gt;Cracking the password-protected ZIP archive with fcrackzip&lt;/h3&gt;

&lt;p&gt;The tool we’ll use for discovering the password to our ZIP file is fcrackzip. We’ll use the &lt;code&gt;-v&lt;/code&gt; option to generate verbose output and keep track of what it’s doing, and &lt;code&gt;-u&lt;/code&gt;, which tells fcrackzip to attempt to use the guessed password to unzip the file to verify that it is correct and reduce the risk of false positives.&lt;/p&gt;

&lt;p&gt;We have two options as to how fcrackzip will attempt to guess the password. Firstly, we can use the &lt;code&gt;-b&lt;/code&gt; option to perform a brute force attack, guessing every possible combination of characters. This is useful for cracking long, unique passwords, but not the quickest method if you think the password may actually just be a simple combination of words, numbers, and symbols.&lt;/p&gt;

&lt;p&gt;For these scenarios, we’d be better off performing a dictionary attack with &lt;code&gt;-D&lt;/code&gt;. This guesses the password by trying every entry in a list of passwords. As such, fcrackzip requires you to provide a dictionary to use with &lt;code&gt;-p&lt;/code&gt;. We’ll use &lt;a href=&quot;https://github.com/brannondorsey/naive-hashcat/releases/download/data/rockyou.txt&quot; taget=&quot;_blank&quot;&gt;the popular &lt;code&gt;rockyou.txt&lt;/code&gt; dictionary&lt;/a&gt; - a mainstay of the cyber security profession.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;fcrackzip&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rockyou&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;txt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;archive&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;When we hit return, fcrackzip will begin trying every password in the dictionary. When one of them successfully unzips the archive, it will stop and tell us what it is. The duration of this process depends on the dictionary, your computer’s processing power, and the password’s complexity, but in our case the password is so simple that we see results almost instantly.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/wp-content/uploads/2020/09/fcrackzip_2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To view the contents of the archive, all we would have to do is copy the password from the output, open the ZIP file in the Linux GUI, and paste it into the password field when prompted. Then voilà - we’d have our flag, attacker-encrypted data, or any other files we were trying to access.&lt;/p&gt;</content><author><name>mattcasmith</name></author><summary type="html">I recently took part in a DFIR capture the flag with some colleagues. Participants were provided with a system disk image and asked to mount it and complete a number of challenges to discover various flags hidden within the data. Exercises like this are always both a lot of fun and a good way to share knowledge and learn - after all, there’s no better time to pick up new techniques than in the heat of competition. I got most of the answers and finished joint second. One of the questions I didn’t have time for, which I deprioritised as I would have needed to look up the methodology, involved discovering the password to an encrypted ZIP file to access the flag inside. To make sure I can complete similar challenges in future CTFs (or live scenarios), I decided to do some digging, crack a ZIP, and document my method. Creating a password-protected ZIP archive To emulate the conditions of the CTF, I needed to create a ZIP archive containing a text file with the would-be flag. Creating the text file is a simple as using echo to write some content to a file. echo &quot;This is a secret file.&quot; &amp;gt; secretfile.txt We can then use 7-Zip to create a password-protected ZIP archive. The a option tells 7-Zip that we’re adding files to an archive. We then specify the name of the archive and the file we wish to add. Finally, the -p option allows us to add a password - in this case, the very secure thisisapassword. Also note that the lack of a space isn’t a typo - that’s just the way 7-Zip wants the information to be provided. 7z a archive.zip secretfile.txt -pthisisapassword Now let’s check that the password was properly applied to the archive using the GUI. We can see that if we open archive.zip, we can see the file listing inside, but if we double-click to open any of the files we receive a prompt and cannot see the contents without entering the correct password. Cracking the password-protected ZIP archive with fcrackzip The tool we’ll use for discovering the password to our ZIP file is fcrackzip. We’ll use the -v option to generate verbose output and keep track of what it’s doing, and -u, which tells fcrackzip to attempt to use the guessed password to unzip the file to verify that it is correct and reduce the risk of false positives. We have two options as to how fcrackzip will attempt to guess the password. Firstly, we can use the -b option to perform a brute force attack, guessing every possible combination of characters. This is useful for cracking long, unique passwords, but not the quickest method if you think the password may actually just be a simple combination of words, numbers, and symbols. For these scenarios, we’d be better off performing a dictionary attack with -D. This guesses the password by trying every entry in a list of passwords. As such, fcrackzip requires you to provide a dictionary to use with -p. We’ll use the popular rockyou.txt dictionary - a mainstay of the cyber security profession. fcrackzip -D -p rockyou.txt -v -u archive.zip When we hit return, fcrackzip will begin trying every password in the dictionary. When one of them successfully unzips the archive, it will stop and tell us what it is. The duration of this process depends on the dictionary, your computer’s processing power, and the password’s complexity, but in our case the password is so simple that we see results almost instantly. To view the contents of the archive, all we would have to do is copy the password from the output, open the ZIP file in the Linux GUI, and paste it into the password field when prompted. Then voilà - we’d have our flag, attacker-encrypted data, or any other files we were trying to access.</summary></entry><entry><title type="html">Network connections and packet crafting on the Linux command line</title><link href="https://mattcasmith.net/2020/08/27/network-connections-packet-crafting-linux-command-line" rel="alternate" type="text/html" title="Network connections and packet crafting on the Linux command line" /><published>2020-09-02T01:00:00+01:00</published><updated>2020-09-02T01:00:00+01:00</updated><id>https://mattcasmith.net/2020/08/27/network-connections-packet-crafting-linux-command-line</id><content type="html" xml:base="https://mattcasmith.net/2020/08/27/network-connections-packet-crafting-linux-command-line">&lt;p&gt;The problem with taking leave during a pandemic is that there are very few places you can go that don’t present an unnecessary risk. For me at least, the thought of taking a plane abroad wasn’t appealing, and neither were the Tube journeys that would be necessary to go out and about in London. To save myself from three weeks of &lt;a href=&quot;http://mattcasmith.net/2019/01/25/football-manager-addictive-spreadsheet/&quot;&gt;&lt;em&gt;Football Manager&lt;/em&gt;&lt;/a&gt; and repeats of &lt;em&gt;The Office&lt;/em&gt;, I stocked up on cyber security books.&lt;/p&gt;

&lt;p&gt;I finally completed my first runthrough of &lt;a href=&quot;https://www.amazon.co.uk/CISSP-Certified-Information-Security-Professional/dp/1119475937/&quot; target=&quot;_blank&quot;&gt;the mammoth CISSP study guide&lt;/a&gt;, brushed up on my PowerShell with &lt;a href=&quot;https://nostarch.com/powershellsysadmins&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;PowerShell for Sysadmins&lt;/em&gt;&lt;/a&gt;, and took some time to improve my Wireshark skills with &lt;a href=&quot;https://nostarch.com/packetanalysis3&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;Practical Packet Analysis&lt;/em&gt;&lt;/a&gt;. The latter was certainly my favourite - Chris Sanders’ book serves as both a very practical exploration of packet analysis and just about the best introduction to networking fundamentals I’ve come across. It’s certainly one I’ll be recommending to my colleagues when I return to the (virtual) office.&lt;/p&gt;

&lt;p&gt;When I finished &lt;em&gt;Practical Packet Analysis&lt;/em&gt;, I decided I wanted to increase my familiarity not only with Wireshark and analysis techniques, but also how the packets are generated in the first place. It’s easy enough to run &lt;code&gt;ping&lt;/code&gt; or &lt;code&gt;nslookup&lt;/code&gt; and observe the results, but when it came to manually crafting packets I was only vaguely aware of where to start, and it seemed like a useful area to explore. So I fired up a couple of Linux virtual machines, opened Google, and got searching for tools and tutorials to help me.&lt;/p&gt;

&lt;p&gt;Below is a brief overview of some of the tools I experimented with. Some of them allow you to create packets, others TCP connections - but all of them are worth spending some time with to send some packets, generate some PCAPs, and learn more about how your network functions.&lt;/p&gt;

&lt;h3 id=&quot;contents&quot;&gt;Contents&lt;/h3&gt;
&lt;p&gt;1. &lt;a href=&quot;#netcat&quot;&gt;netcat&lt;/a&gt;&lt;br /&gt;
2. &lt;a href=&quot;#bash&quot;&gt;Bash&lt;/a&gt;&lt;br /&gt;
3. &lt;a href=&quot;#scapy&quot;&gt;Scapy&lt;/a&gt;&lt;br /&gt;
4. &lt;a href=&quot;#sendip&quot;&gt;SendIp&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;netcat&quot;&gt;netcat&lt;/h3&gt;

&lt;p&gt;Let’s start with a classic. A favourite among cyber security professionals, &lt;code&gt;netcat&lt;/code&gt; is a tool that can be used to send and receive data between systems, either via TCP or via UDP with the &lt;code&gt;-u&lt;/code&gt; flag. A listener is set up using the &lt;code&gt;-l&lt;/code&gt; flag - for example, the command below would start a listener on UDP port 372.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lu&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;372&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;With this system listening for UDP datagrams on port 372, we can now use &lt;code&gt;netcat&lt;/code&gt; to send data from a second system. The command to begin sending data is quite similar to the one for setting up the listener - just this time we remove the &lt;code&gt;-l&lt;/code&gt; flag and specify the IP address we want to transmit the data to.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;192.168&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;234.128&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;372&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Any text that is sent over the new connection is displayed almost immediately in the terminal of the receiving machine, which is fine if you’re sitting watching the Linux terminal and waiting for quite a short message, as in the example communication between the two VMs below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/wp-content/uploads/2020/09/netcat_1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The beauty of Linux, however, is that we can easily chain together commands to achieve more than they could individually. Let’s say we want to send an image file via &lt;code&gt;netcat&lt;/code&gt;, for example. We can use &lt;code&gt;&amp;gt;&lt;/code&gt; and &lt;code&gt;|&lt;/code&gt; to read the contents of the file on the sending machine and save it on the receiving machine. To receive the image via a TCP connection on port 555, the recipient would use the following command.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;555&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;received_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;png&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The sender would do almost the exact opposite, piping the contents of the original image file to the &lt;code&gt;netcat&lt;/code&gt; connection in order to transmit it over the network to the recipient’s system.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image_to_send&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;png&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nc&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;192.168&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;234.128&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;555&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;code&gt;cat&lt;/code&gt; reads the contents of the image file, which are piped to our &lt;code&gt;netcat&lt;/code&gt; connection. The receiving system sends the data received over the connection to its own image file, and when we check the file itself via the GUI we can see that the image data was successfully transmitted and saved to disk.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/wp-content/uploads/2020/09/netcat_2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;These examples only scratch the surface of what is possible with &lt;code&gt;netcat&lt;/code&gt;, and I’d encourage you to play around with it to see what it is capable of. SANS has &lt;a taget=&quot;_blank&quot; href=&quot;https://www.sans.org/security-resources/sec560/netcat_cheat_sheet_v1.pdf&quot;&gt;a particularly handy cheat sheet&lt;/a&gt; with common commands and accepted flags and options to help you get started.&lt;/p&gt;

&lt;h3 id=&quot;bash&quot;&gt;Bash&lt;/h3&gt;

&lt;p&gt;While we’re on the topic of sending messages and files over the network, it’s also worth noting that the Linux Bash terminal actually has a built-in capability for this using &lt;code&gt;/dev/tcp/&lt;/code&gt; and &lt;code&gt;/dev/udp/&lt;/code&gt;. Simply add an IP address and port and send your data to this directory, and Linux will handle the rest.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Hello. I'm sending this from the Linux terminal.&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tcp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;192.168&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;234.128&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;824&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;In this example, I’ve used &lt;code&gt;echo&lt;/code&gt; to send a text message over the network, but I could equally have used &lt;code&gt;cat&lt;/code&gt; and a filename to send a file like we did with &lt;code&gt;netcat&lt;/code&gt;. A &lt;code&gt;netcat&lt;/code&gt; listener on the recipient’s system receives the message and outputs it to the terminal as in our first &lt;code&gt;netcat&lt;/code&gt; example.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/wp-content/uploads/2020/09/bash_1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Did you notice the small difference in the output above? When all the data has been received, the TCP connection is closed and the listener stops. If we were expecting to receive more data later, we could use &lt;code&gt;netcat&lt;/code&gt;’s &lt;code&gt;-k&lt;/code&gt; flag, which would keep the listener active. The TCP connection is still closed when the transfer is complete, but the listener persists and allows the creation of additional TCP connections as they are needed in response to connection requests from clients.&lt;/p&gt;

&lt;p&gt;Another difference to using &lt;code&gt;netcat&lt;/code&gt; to send data was that we did not need to use &lt;code&gt;sudo&lt;/code&gt; to send data from a TCP port using &lt;code&gt;/dev/tcp/&lt;/code&gt; - useful to know for scenarios where there are restrictions in place.&lt;/p&gt;

&lt;h3 id=&quot;scapy&quot;&gt;Scapy&lt;/h3&gt;

&lt;p&gt;Now let’s move down a level and take a look at some tools for manually crafting packets. &lt;a href=&quot;https://scapy.net/&quot; target=&quot;_blank&quot;&gt;Scapy&lt;/a&gt; is a Python tool that allows you to send custom packets, individually manipulating fields and flags via a series of commands and options to send exactly the data you want - very useful for testing.&lt;/p&gt;

&lt;p&gt;Let’s say I want to check &lt;a href=&quot;http://mattcasmith.net/2020/02/15/pi-hole-samsung-smart-tv/&quot;&gt;my Pi-hole DNS server&lt;/a&gt; is functioning correctly and returning responses when it receives queries. I can manually craft a DNS request for my domain, &lt;code&gt;www.mattcasmith.net&lt;/code&gt;, using the following command within Scapy to specify fields like the destination address/port and DNS query.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dst&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;{pihole_ip}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UDP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dport&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;53&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;qd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DNSQR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;qname&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;www.mattcasmith.net&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;I specify the Pi-hole’s IP address and the UDP port 53 (used for DNS) as the destination, and provide the domain to be queried with the &lt;code&gt;qname&lt;/code&gt; parameter. If all goes well, Scapy will send the packet to the DNS server and print the packet it receives in response, as below. If we wanted to review this data in a nicer format, we could also have run Wireshark or &lt;code&gt;tcpdump&lt;/code&gt; at the same time to generate a PCAP.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/wp-content/uploads/2020/09/scapy_1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;By reviewing the response above, we can see that the Pi-hole has successfully returned a response. Between the &lt;code&gt;DNSRR&lt;/code&gt; tags we can see that the DNS server has returned several IP addresses associated with the domain, as we’d see in the output of a tool like &lt;code&gt;nslookup&lt;/code&gt; or &lt;code&gt;dig&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;sendip&quot;&gt;SendIp&lt;/h3&gt;

&lt;p&gt;Another means to the same end is &lt;a href=&quot;https://www-x.antd.nist.gov/ipv6/sendip.html&quot; target=&quot;_blank&quot;&gt;SendIp&lt;/a&gt; - a Linux command line tool that enables you to craft custom packets in a similar way to Scapy. Rather than sending another DNS query, let’s go back to an earlier example and set up a &lt;code&gt;netcat&lt;/code&gt; listener on UDP port 904 to receive a text message.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sendip&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ipv4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;192.168&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;234.130&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;udp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;us&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5070&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ud&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;904&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;This is a datagram sent with sendip from the command line.&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;192.168&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;234.128&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The length of the SendIp command reflects the additional flexibility we have compared to when we sent a similar message with &lt;code&gt;netcat&lt;/code&gt;. The &lt;code&gt;-p&lt;/code&gt; flag sets our protocols - in this case IPv4 at the network layer and UDP at the transport layer - and after each we specify the contents of various header fields.&lt;/p&gt;

&lt;p&gt;Notice that SendIP allows us to set the IP source address manually with &lt;code&gt;-is&lt;/code&gt; as well as the UDP source port with &lt;code&gt;-us&lt;/code&gt;. In testing scenarios, including penetration tests, this would allow us to spoof packets from different machines, with much greater control over the packet and header contents than with &lt;code&gt;netcat&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Finally, the &lt;code&gt;-d&lt;/code&gt; flag declares the contents of the packet payload - in this case the text message, which we can see in the output on the recipient’s system is received by the &lt;code&gt;netcat&lt;/code&gt; listener.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/wp-content/uploads/2020/09/sendip_1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;All of the tools and examples above represent different ways of sending data over a network from the Linux command line. While I used simple text and file exchanges to demonstrate how they work, these tools have many different features and options and can be used in much more complex scenarios. Hopefully this post has given you some idea of how they work and what they are capable of, and given you enough of a starting point to try some experiments of your own.&lt;/p&gt;</content><author><name>mattcasmith</name></author><summary type="html">The problem with taking leave during a pandemic is that there are very few places you can go that don’t present an unnecessary risk. For me at least, the thought of taking a plane abroad wasn’t appealing, and neither were the Tube journeys that would be necessary to go out and about in London. To save myself from three weeks of Football Manager and repeats of The Office, I stocked up on cyber security books. I finally completed my first runthrough of the mammoth CISSP study guide, brushed up on my PowerShell with PowerShell for Sysadmins, and took some time to improve my Wireshark skills with Practical Packet Analysis. The latter was certainly my favourite - Chris Sanders’ book serves as both a very practical exploration of packet analysis and just about the best introduction to networking fundamentals I’ve come across. It’s certainly one I’ll be recommending to my colleagues when I return to the (virtual) office. When I finished Practical Packet Analysis, I decided I wanted to increase my familiarity not only with Wireshark and analysis techniques, but also how the packets are generated in the first place. It’s easy enough to run ping or nslookup and observe the results, but when it came to manually crafting packets I was only vaguely aware of where to start, and it seemed like a useful area to explore. So I fired up a couple of Linux virtual machines, opened Google, and got searching for tools and tutorials to help me. Below is a brief overview of some of the tools I experimented with. Some of them allow you to create packets, others TCP connections - but all of them are worth spending some time with to send some packets, generate some PCAPs, and learn more about how your network functions. Contents 1. netcat 2. Bash 3. Scapy 4. SendIp netcat Let’s start with a classic. A favourite among cyber security professionals, netcat is a tool that can be used to send and receive data between systems, either via TCP or via UDP with the -u flag. A listener is set up using the -l flag - for example, the command below would start a listener on UDP port 372. sudo nc -lu 372 With this system listening for UDP datagrams on port 372, we can now use netcat to send data from a second system. The command to begin sending data is quite similar to the one for setting up the listener - just this time we remove the -l flag and specify the IP address we want to transmit the data to. sudo nc -u 192.168.234.128 372 Any text that is sent over the new connection is displayed almost immediately in the terminal of the receiving machine, which is fine if you’re sitting watching the Linux terminal and waiting for quite a short message, as in the example communication between the two VMs below. The beauty of Linux, however, is that we can easily chain together commands to achieve more than they could individually. Let’s say we want to send an image file via netcat, for example. We can use &amp;gt; and | to read the contents of the file on the sending machine and save it on the receiving machine. To receive the image via a TCP connection on port 555, the recipient would use the following command. sudo nc -l 555 &amp;gt; received_image.png The sender would do almost the exact opposite, piping the contents of the original image file to the netcat connection in order to transmit it over the network to the recipient’s system. cat image_to_send.png | sudo nc 192.168.234.128 555 cat reads the contents of the image file, which are piped to our netcat connection. The receiving system sends the data received over the connection to its own image file, and when we check the file itself via the GUI we can see that the image data was successfully transmitted and saved to disk. These examples only scratch the surface of what is possible with netcat, and I’d encourage you to play around with it to see what it is capable of. SANS has a particularly handy cheat sheet with common commands and accepted flags and options to help you get started. Bash While we’re on the topic of sending messages and files over the network, it’s also worth noting that the Linux Bash terminal actually has a built-in capability for this using /dev/tcp/ and /dev/udp/. Simply add an IP address and port and send your data to this directory, and Linux will handle the rest. echo &quot;Hello. I'm sending this from the Linux terminal.&quot; &amp;gt; /dev/tcp/192.168.234.128/824 In this example, I’ve used echo to send a text message over the network, but I could equally have used cat and a filename to send a file like we did with netcat. A netcat listener on the recipient’s system receives the message and outputs it to the terminal as in our first netcat example. Did you notice the small difference in the output above? When all the data has been received, the TCP connection is closed and the listener stops. If we were expecting to receive more data later, we could use netcat’s -k flag, which would keep the listener active. The TCP connection is still closed when the transfer is complete, but the listener persists and allows the creation of additional TCP connections as they are needed in response to connection requests from clients. Another difference to using netcat to send data was that we did not need to use sudo to send data from a TCP port using /dev/tcp/ - useful to know for scenarios where there are restrictions in place. Scapy Now let’s move down a level and take a look at some tools for manually crafting packets. Scapy is a Python tool that allows you to send custom packets, individually manipulating fields and flags via a series of commands and options to send exactly the data you want - very useful for testing. Let’s say I want to check my Pi-hole DNS server is functioning correctly and returning responses when it receives queries. I can manually craft a DNS request for my domain, www.mattcasmith.net, using the following command within Scapy to specify fields like the destination address/port and DNS query. (dst=&quot;{pihole_ip}&quot;)/UDP(dport=53)/DNS(rd=1,qd=DNSQR(qname=&quot;www.mattcasmith.net&quot;)),verbose=0) I specify the Pi-hole’s IP address and the UDP port 53 (used for DNS) as the destination, and provide the domain to be queried with the qname parameter. If all goes well, Scapy will send the packet to the DNS server and print the packet it receives in response, as below. If we wanted to review this data in a nicer format, we could also have run Wireshark or tcpdump at the same time to generate a PCAP. By reviewing the response above, we can see that the Pi-hole has successfully returned a response. Between the DNSRR tags we can see that the DNS server has returned several IP addresses associated with the domain, as we’d see in the output of a tool like nslookup or dig. SendIp Another means to the same end is SendIp - a Linux command line tool that enables you to craft custom packets in a similar way to Scapy. Rather than sending another DNS query, let’s go back to an earlier example and set up a netcat listener on UDP port 904 to receive a text message. sudo sendip -p ipv4 -is 192.168.234.130 -p udp -us 5070 -ud 904 -d &quot;This is a datagram sent with sendip from the command line.&quot; -v 192.168.234.128 The length of the SendIp command reflects the additional flexibility we have compared to when we sent a similar message with netcat. The -p flag sets our protocols - in this case IPv4 at the network layer and UDP at the transport layer - and after each we specify the contents of various header fields. Notice that SendIP allows us to set the IP source address manually with -is as well as the UDP source port with -us. In testing scenarios, including penetration tests, this would allow us to spoof packets from different machines, with much greater control over the packet and header contents than with netcat. Finally, the -d flag declares the contents of the packet payload - in this case the text message, which we can see in the output on the recipient’s system is received by the netcat listener. All of the tools and examples above represent different ways of sending data over a network from the Linux command line. While I used simple text and file exchanges to demonstrate how they work, these tools have many different features and options and can be used in much more complex scenarios. Hopefully this post has given you some idea of how they work and what they are capable of, and given you enough of a starting point to try some experiments of your own.</summary></entry><entry><title type="html">Technicolor TG582n router: The missing event logging manual</title><link href="https://mattcasmith.net/2020/07/18/technicolor-tg582n-event-logging-manual" rel="alternate" type="text/html" title="Technicolor TG582n router&amp;#58; The missing event logging manual" /><published>2020-07-18T00:00:00+01:00</published><updated>2020-07-18T00:00:00+01:00</updated><id>https://mattcasmith.net/2020/07/18/technicolor-tg582n-missing-event-logging-manual</id><content type="html" xml:base="https://mattcasmith.net/2020/07/18/technicolor-tg582n-event-logging-manual">&lt;p&gt;What started as curiosity has turned into something of a labour of love. Online information about the Technicolor TG582n router’s event logging capabilities is scarce, and scattered across a number of forums. I’ve used that information along with some analysis of my own to compile this - the missing event logging manual - in the hope that it might help others to expore their routers’ event logs in future.&lt;/p&gt;

&lt;h3 id=&quot;contents&quot;&gt;Contents&lt;/h3&gt;
&lt;p&gt;1. &lt;a href=&quot;#background&quot;&gt;Background&lt;/a&gt;&lt;br /&gt;
2. &lt;a href=&quot;#forwarding-technicolor-tg582n-event-logs&quot;&gt;Forwarding Technicolor TG582n event logs&lt;/a&gt;&lt;br /&gt;
3. &lt;a href=&quot;#useful-events-from-the-technicolor-tg582n&quot;&gt;Useful events from the Technicolor TG582n&lt;/a&gt;&lt;br /&gt;
          a. &lt;a href=&quot;#internet-connection-events&quot;&gt;Internet connection events&lt;/a&gt;&lt;br /&gt;
          b. &lt;a href=&quot;#wifi-authentication-events&quot;&gt;WiFi authentication events&lt;/a&gt;&lt;br /&gt;
          c. &lt;a href=&quot;#admin-authentication-events&quot;&gt;Admin authentication events&lt;/a&gt;&lt;br /&gt;
          d. &lt;a href=&quot;#firewall-events&quot;&gt;Firewall events&lt;/a&gt;&lt;br /&gt;
          e. &lt;a href=&quot;#intrusion-detection-system-ids-events&quot;&gt;Intrusion detection system (IDS) events&lt;/a&gt;&lt;br /&gt;
4. &lt;a href=&quot;#example-investigation-using-technicolor-tg582n-events&quot;&gt;Example investigation using Technicolor TG582n events&lt;/a&gt;&lt;br /&gt;
5. &lt;a href=&quot;#contribute&quot;&gt;Contribute&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;The Technicolor TG582n is a common sight in British homes - and, if internet forums are a fair reflection of reality, homes in several other countries, too. It is, or was, the default ADSL router for a number of internet service providers (ISPs) and seems to be a common option to distribute to customers on bog standard tariffs who haven’t earned the Home Hubs and Sky Hubs of this world.&lt;/p&gt;

&lt;p&gt;I used this router for several years (hence why I had one laying around) and as I grew more interested in cyber security I remember searching around several times for any information I could find regarding its logging capabilities and finding very little. So with a little more digging and the additional knowledge I’ve gained via experience since then, I thought I might be able to assemble something of a manual for anyone still using this router who wants to explore its event log and monitor their network activity.&lt;/p&gt;

&lt;p&gt;With that mission in mind, and safe in the knowledge that even bricking the device would have no repercussions for my internet access now I had a new router, I set out to find how to gather logs from the Technicolor TG282n and to aggregate enough of them that I could give an overview of some of the most common events generated by the little box, which until then had been gathering dust in a cupboard.&lt;/p&gt;

&lt;h3 id=&quot;forwarding-technicolor-tg582n-event-logs&quot;&gt;Forwarding Technicolor TG582n event logs&lt;/h3&gt;

&lt;p&gt;While there may not be a manual for the Technicolor TG582n router’s event logging capabilities, there &lt;em&gt;is&lt;/em&gt; &lt;a href=&quot;https://www.manualslib.com/products/Technicolor-Tg582n-3530624.html&quot; target=&quot;_blank&quot;&gt;a manual for its Telnet interface&lt;/a&gt;. That’s right - the manufacturer is forcing us to send our administrative credentials over an unencrypted protocol to configure the router, so make sure you don’t do this if there’s a chance anyone malicious is on your network. When we log in, we’re greeted with some nice ASCII art.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/wp-content/uploads/2020/07/technicolor-tg582n.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Beautiful. Now let’s turn our attention to turning on the event log. If you’re in a hurry and just want to grab recent events, you can use the command below to send whatever events are in the router’s cache to your analysis machine via syslog. Make sure you have something listening on port 514 to receive them.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;syslog&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;msgbuf&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;send&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;But we’re looking for something a little longer lasting. Luckily, the Technicolor TG582n has a system for managing event log rules and a series of commands to view the rules, add new rules, remove rules, and start and stop the logging service. To set all events to be transmitted via syslog regardless of the service that generated them or their severity, enter the following commands.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;syslog&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ruleadd&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fac&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;all&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;debug&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;syslog&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;syslog&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enabled&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The first command adds a syslog rule on the router. It gathers events from all facilities (or services) and at all severity levels (debug being the lowest) and transmits them via syslog to the destination IP address specified. The second command displays the list of syslog rules so we can make sure the rule was added correctly, and the final one enables the syslog service so events will begin to be transmitted.&lt;/p&gt;

&lt;p&gt;Naturally, this means that once again we’ll need a service listening on port 514 on the destination system. If you’re sending logs for a quick check then &lt;a href=&quot;https://www.wireshark.org/&quot; target=&quot;_blank&quot;&gt;Wireshark&lt;/a&gt; is probably enough. I was looking to gather events from a longer period of time to identify as many event types as possible, so I set up &lt;a href=&quot;https://www.elastic.co/logstash&quot; target=&quot;_blank&quot;&gt;Logstash&lt;/a&gt; to receive the syslog and write the events to a file I could analyse later. A syslog server is another alternative.&lt;/p&gt;

&lt;h3 id=&quot;useful-events-from-the-technicolor-tg582n&quot;&gt;Useful events from the Technicolor TG582n&lt;/h3&gt;

&lt;p&gt;After leaving the syslog service and Logstash running for about a week, I opened the log file in Excel and manipulated the contents into a format that would enable me to filter them down to unique event types. What follows are some of the most useful and/or interesting events I picked out from the logs.&lt;/p&gt;

&lt;h4 id=&quot;internet-connection-events&quot;&gt;Internet connection events&lt;/h4&gt;

&lt;p&gt;Let’s start with the basics. Most times you check your router logs, you’re likely to be investigating connectivity issues and checking to see whether you have an internet connection. These events relating to the point-to-point protocol (PPP) will hopefully provide you with an answer.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;PPP&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;link&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;down&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Internet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;PPP&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CHAP&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;receive&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;challenge&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rhost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_hostname&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;PPP&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CHAP&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chap&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;receive&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;success&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;authentication&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ok&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;PPP&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;link&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;up&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Internet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The first event is the one you’ll hope not to see. As the &lt;code&gt;link down&lt;/code&gt; message suggests, this event is generated when your internet connection fails and you no longer have a connection to your ISP.&lt;/p&gt;

&lt;p&gt;The next two events are generated when you try to reconnect and relate to the challenge-handshake authentication protocol (CHAP). Your router recieves an authentication challenge from your ISP, provides your credentials, and gets an &lt;code&gt;authentication ok&lt;/code&gt; response if everything checks out. Then you’ll see the final &lt;code&gt;link up&lt;/code&gt; event when the internet connection is back up and running.&lt;/p&gt;

&lt;h4 id=&quot;wifi-authentication-events&quot;&gt;WiFi authentication events&lt;/h4&gt;

&lt;p&gt;As soon as I started scanning the logs, one event stood out as potentially useful in catching perhaps the most common of wireless network attacks: unauthorised attempts to access the WiFi network.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;LOGIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wireless&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;station&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mac_address&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;can&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'t get authorized&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;There’s some debate online about exactly what this event means, and people have seen it pop up in all sorts of unexpected ways (including one forum user whose stolen PlayStation 3 was apparently haunting his router and failing to connect to the network on a regular basis).&lt;/p&gt;

&lt;p&gt;Although it sounds like it might refer to an access point, a “wireless station” in networking jargon is actually a device that can join the wireless network. In my case these events all featured the MAC address of an Apple device - and not one of my own - so that would be an obvious one to block, just to be safe.&lt;/p&gt;

&lt;h4 id=&quot;admin-authentication-events&quot;&gt;Admin authentication events&lt;/h4&gt;

&lt;p&gt;The bread and butter of security event logging is authentication: who is logging in and out of your system and who is failing to log in using an incorrect password? This is doubly important for admin accounts, and the Technicolor TG582n’s syslog has got you covered with a few takes on these common events.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;LOGIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;User&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;username&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logged&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TELNET&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;LOGOUT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;User&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;username&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logged&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TELNET&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;LOGIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;User&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;username&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tried&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TELNET&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;SESSION&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TIMEOUT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Timeout&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;after&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;600&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The first two events are what you would expect to see for a normal administrative session - one for when the user logs in and one for when they log out. The important thing is that Technicolor has included the username and the source IP address, which are key details if you’re planning to apply any kind of detection logic to these logs or even manually trying to investigate potential attacks.&lt;/p&gt;

&lt;p&gt;The third event is misleading. A user “tried to” log in? Many devices would follow this up with an authentication success or failure event, but in this case it actually signifies a failed login by itself. Unfortunately, while we again get the username and source IP address, we do not get one critical detail: whether the failure was due to a bad username or an incorrect password.&lt;/p&gt;

&lt;p&gt;Finally, we have an event that may help to track user sessions that do not end with a &lt;code&gt;LOGOUT&lt;/code&gt; event. When the Telnet connection is left idle for a while, the Technicolor TG582n eventually closes it, and it seems that’s when this event is created. It’s unlikely to pop up too often, but still potentially useful to know.&lt;/p&gt;

&lt;h4 id=&quot;firewall-events&quot;&gt;Firewall events&lt;/h4&gt;

&lt;p&gt;The firewall is in charge of allowing or denying traffic based on its source and destination and the connection type. First up, here the the events that the Technicolor TG582n generates when somebody makes changes to its firewall rules. As you can see, they’re fairly self-explanatory.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;FIREWALL&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;created&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rules&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;FIREWALL&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;modified&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rules&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;FIREWALL&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;event&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;deleted&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rules&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;As you might suspect, these are generated when firewall rules are created, modified, and deleted respectively. One thing to watch out for with these, however, is that all three events seem to be generated in this order when a connection to the internet is established. So don’t be surprised if you see them crop up at points in the logs that you weren’t expecting them if the router was connecting to your ISP. Their effect will also require some investigation, as they don’t actually state &lt;em&gt;which&lt;/em&gt; rules were changed.&lt;/p&gt;

&lt;p&gt;Next, let’s look at the firewall in action. In the week the router was active, the firewall sprung into action on the following three occasions, all of which related to internet control message protocol (ICMP) traffic.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;FIREWALL&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replay&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Protocol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ICMP&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;Src&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dst&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Destination&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Unreachable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Code&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Port&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Unreacheable&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;FIREWALL&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;icmp&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Protocol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ICMP&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;Src&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dst&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Destination&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Unreachable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Code&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Port&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Unreacheable&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;FIREWALL&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;icmp&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Protocol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ICMP&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;Src&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dst&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Echo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Reply&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Code&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Unfortunately there’s no authority on what these actually mean. I’d expect a “replay check” to attempt to stop replay attacks, but the leading theory on the forums seems to be that this event means the firewall has prevented your router from providing a response to an ICMP ping from an attacker performing reconnaissance and attempting to discover information about your network. I have, however, also seen this occurring on outbound traffic to DNS servers from &lt;a href=&quot;/2020/02/15/pi-hole-samsung-smart-tv/&quot;&gt;my Pi-hole&lt;/a&gt;, so your guess is as good as mine and any additional information anyone might be able to share would be appreciated.&lt;/p&gt;

&lt;h4 id=&quot;intrusion-detection-system-ids-events&quot;&gt;Intrusion detection system (IDS) events&lt;/h4&gt;

&lt;p&gt;There’s a reason they say to start with your home network if you want to learn about cyber security. Looking through the IDS log will give you a nice insight into all the potentially nasty stuff targeting your network and give you a newfound appreciation for all the work your little Technicolor TG582n does.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;IDS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dos&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idp&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flood&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0801&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;UDP&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;-&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;IDS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tcp&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;limiting&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;   &lt;span class=&quot;mi&quot;&gt;0040&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TCP&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;-&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.....]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;win&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;IDS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scan&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tcp&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;port&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scanned&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;least&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ports&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;   &lt;span class=&quot;mi&quot;&gt;0040&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TCP&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;-&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[...&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;..]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11694198&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;win&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;IDS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scan&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;udp&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;port&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scanned&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;least&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ports&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;   &lt;span class=&quot;mi&quot;&gt;0441&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;UDP&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;-&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;IDS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scan&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tcp&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;syn&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scanned&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;least&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ports&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;   &lt;span class=&quot;mi&quot;&gt;0040&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TCP&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;-&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.....]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;97417629&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;win&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;IDS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;proto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tcp&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;port&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;   &lt;span class=&quot;mi&quot;&gt;0040&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TCP&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;-&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.....]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2505992964&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;win&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The IDS appears to have detection rules for potential denial of service (DoS) attacks. In the first event, too many UDP packets were detected between the same IP addresses. This typically appears to be followed up by a UDP rate limiting event as the router attempts to protect the network against the perceived attack. What’s pretty cool is that this also appears to apply to outgoing traffic, so if your devices become infected and form part of a botnet they are prevented from spamming the attackers’ targets with packets.&lt;/p&gt;

&lt;p&gt;The second event in my sample concerns TCP rate limiting and in my logs was applied to an IP address from Russia. An IDS applies rate limiting when it receives a large number of connection requests from a particular IP address and applies a temporary block to avoid a denial of service (DoS) condition. Note that this wouldn’t stop a distributed denial of service (DDoS) attack, which achieves the same result by sending a smaller number of packets from each of a large number of IP addresses.&lt;/p&gt;

&lt;p&gt;Then we have various types of detected port scans - in my case detected from IP addresses belonging to organisations as varied as Akamai, Amazon, GoDaddy, and Twitch, as well as a few IP addresses that looked like Russian hackers. Not much you can do about that, but it’s interesting stuff nonetheless.&lt;/p&gt;

&lt;p&gt;Finally, we have a TCP null port packet detection (in my logs the destination port showed up as 0). I couldn’t find too much information about this, but it’s likely to be a sign that an attacker is crafting nonsensical packets in an attempt to elicit an abnormal response from the router.&lt;/p&gt;

&lt;h3 id=&quot;example-investigation-using-technicolor-tg582n-events&quot;&gt;Example investigation using Technicolor TG582n events&lt;/h3&gt;

&lt;p&gt;Where does knowing all this get you? Having visibility of your router events and understanding what they mean can help you to troubleshoot network issues and identify potential cyber attacks - anything from sophisticated intruders to neighbours hijacking your broadband connection.&lt;/p&gt;

&lt;p&gt;As an example of how the Technicolor TG582n’s event logs can come in useful, during the week I was running the router I noticed a potential problem. Like many others during the COVID-19 pandemic, I was working from home, and my Skype video calls would drop out seemingly randomly. I decided to do some digging in the new logs for any clues, and here’s what I found at around the time of one of my failed calls…&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;IDS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dos&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;udp&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flood&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;company_server_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0801&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;UDP&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;-&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;IDS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;udp&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;limiting&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;company_server_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1072&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;UDP&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;-&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;destination_port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;PPP&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;link&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;down&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Internet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;PPP&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CHAP&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Receive&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;challenge&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rhost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;PPP&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CHAP&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Chap&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;receive&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;success&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;authentication&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ok&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;PPP&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;link&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;up&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Internet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;My best theory is this: The router spotted the large number of UDP datagrams being sent between my system and the Skype server and assumed this was a DoS attack. To put a stop to it, it applied rate limiting to the connection, which disrupted the call. Somewhere along the line this upset &lt;em&gt;something&lt;/em&gt;, and that &lt;em&gt;something&lt;/em&gt; failing took the connection down, meaning I had to wait for the broadband connection to resume before signing back into Skype, reconnecting to the call, and giving my apologies.&lt;/p&gt;

&lt;p&gt;Unfortunately, there’s little that you could do about this particular issue. The Technicolor TG582n gives you the option of turning the IDS on or off, and there is no configuration to be done beyond that - you’re either protected or you’re not. I suppose that means I should be glad that I’ve since upgraded.&lt;/p&gt;

&lt;h3 id=&quot;contribute&quot;&gt;Contribute&lt;/h3&gt;

&lt;p&gt;Event enumeration without proper documentation is often very hit-and-miss. I left the Technicolor TG582n router running for about a week to generate as many different events as possible, but if a certain type of event simply didn’t occur, it won’t have shown up in my analysis. If you have important and/or interesting events to add to this list, please get in touch via the links below and I’ll add them in (with credit!).&lt;/p&gt;</content><author><name>mattcasmith</name></author><category term="Networking" /><category term="Internet" /><category term="Router" /><category term="Logs" /><category term="IDS" /><category term="Firewall" /><summary type="html">What started as curiosity has turned into something of a labour of love. Online information about the Technicolor TG582n router’s event logging capabilities is scarce, and scattered across a number of forums. I’ve used that information along with some analysis of my own to compile this - the missing event logging manual - in the hope that it might help others to expore their routers’ event logs in future. Contents 1. Background 2. Forwarding Technicolor TG582n event logs 3. Useful events from the Technicolor TG582n           a. Internet connection events           b. WiFi authentication events           c. Admin authentication events           d. Firewall events           e. Intrusion detection system (IDS) events 4. Example investigation using Technicolor TG582n events 5. Contribute Background The Technicolor TG582n is a common sight in British homes - and, if internet forums are a fair reflection of reality, homes in several other countries, too. It is, or was, the default ADSL router for a number of internet service providers (ISPs) and seems to be a common option to distribute to customers on bog standard tariffs who haven’t earned the Home Hubs and Sky Hubs of this world. I used this router for several years (hence why I had one laying around) and as I grew more interested in cyber security I remember searching around several times for any information I could find regarding its logging capabilities and finding very little. So with a little more digging and the additional knowledge I’ve gained via experience since then, I thought I might be able to assemble something of a manual for anyone still using this router who wants to explore its event log and monitor their network activity. With that mission in mind, and safe in the knowledge that even bricking the device would have no repercussions for my internet access now I had a new router, I set out to find how to gather logs from the Technicolor TG282n and to aggregate enough of them that I could give an overview of some of the most common events generated by the little box, which until then had been gathering dust in a cupboard. Forwarding Technicolor TG582n event logs While there may not be a manual for the Technicolor TG582n router’s event logging capabilities, there is a manual for its Telnet interface. That’s right - the manufacturer is forcing us to send our administrative credentials over an unencrypted protocol to configure the router, so make sure you don’t do this if there’s a chance anyone malicious is on your network. When we log in, we’re greeted with some nice ASCII art. Beautiful. Now let’s turn our attention to turning on the event log. If you’re in a hurry and just want to grab recent events, you can use the command below to send whatever events are in the router’s cache to your analysis machine via syslog. Make sure you have something listening on port 514 to receive them. syslog msgbuf send dest=&amp;lt;destination_ip&amp;gt; But we’re looking for something a little longer lasting. Luckily, the Technicolor TG582n has a system for managing event log rules and a series of commands to view the rules, add new rules, remove rules, and start and stop the logging service. To set all events to be transmitted via syslog regardless of the service that generated them or their severity, enter the following commands. syslog ruleadd fac=all sev=debug dest=&amp;lt;destination_ip&amp;gt; syslog list syslog config activate=enabled The first command adds a syslog rule on the router. It gathers events from all facilities (or services) and at all severity levels (debug being the lowest) and transmits them via syslog to the destination IP address specified. The second command displays the list of syslog rules so we can make sure the rule was added correctly, and the final one enables the syslog service so events will begin to be transmitted. Naturally, this means that once again we’ll need a service listening on port 514 on the destination system. If you’re sending logs for a quick check then Wireshark is probably enough. I was looking to gather events from a longer period of time to identify as many event types as possible, so I set up Logstash to receive the syslog and write the events to a file I could analyse later. A syslog server is another alternative. Useful events from the Technicolor TG582n After leaving the syslog service and Logstash running for about a week, I opened the log file in Excel and manipulated the contents into a format that would enable me to filter them down to unique event types. What follows are some of the most useful and/or interesting events I picked out from the logs. Internet connection events Let’s start with the basics. Most times you check your router logs, you’re likely to be investigating connectivity issues and checking to see whether you have an internet connection. These events relating to the point-to-point protocol (PPP) will hopefully provide you with an answer. PPP link down (Internet) [&amp;lt;source_ip&amp;gt;] PPP CHAP receive challenge (rhost = &amp;lt;destination_hostname&amp;gt;) PPP CHAP chap receive success : authentication ok PPP link up (Internet) [&amp;lt;source_ip&amp;gt;] The first event is the one you’ll hope not to see. As the link down message suggests, this event is generated when your internet connection fails and you no longer have a connection to your ISP. The next two events are generated when you try to reconnect and relate to the challenge-handshake authentication protocol (CHAP). Your router recieves an authentication challenge from your ISP, provides your credentials, and gets an authentication ok response if everything checks out. Then you’ll see the final link up event when the internet connection is back up and running. WiFi authentication events As soon as I started scanning the logs, one event stood out as potentially useful in catching perhaps the most common of wireless network attacks: unauthorised attempts to access the WiFi network. LOGIN wireless station [&amp;lt;mac_address&amp;gt;] can't get authorized There’s some debate online about exactly what this event means, and people have seen it pop up in all sorts of unexpected ways (including one forum user whose stolen PlayStation 3 was apparently haunting his router and failing to connect to the network on a regular basis). Although it sounds like it might refer to an access point, a “wireless station” in networking jargon is actually a device that can join the wireless network. In my case these events all featured the MAC address of an Apple device - and not one of my own - so that would be an obvious one to block, just to be safe. Admin authentication events The bread and butter of security event logging is authentication: who is logging in and out of your system and who is failing to log in using an incorrect password? This is doubly important for admin accounts, and the Technicolor TG582n’s syslog has got you covered with a few takes on these common events. LOGIN User &amp;lt;username&amp;gt; logged in on TELNET (&amp;lt;source_ip&amp;gt;) LOGOUT User &amp;lt;username&amp;gt; logged out on TELNET (&amp;lt;source_ip&amp;gt;) LOGIN User &amp;lt;username&amp;gt; tried to log in on TELNET (&amp;lt;source_ip&amp;gt;) SESSION TIMEOUT Timeout! (after 600 sec) The first two events are what you would expect to see for a normal administrative session - one for when the user logs in and one for when they log out. The important thing is that Technicolor has included the username and the source IP address, which are key details if you’re planning to apply any kind of detection logic to these logs or even manually trying to investigate potential attacks. The third event is misleading. A user “tried to” log in? Many devices would follow this up with an authentication success or failure event, but in this case it actually signifies a failed login by itself. Unfortunately, while we again get the username and source IP address, we do not get one critical detail: whether the failure was due to a bad username or an incorrect password. Finally, we have an event that may help to track user sessions that do not end with a LOGOUT event. When the Telnet connection is left idle for a while, the Technicolor TG582n eventually closes it, and it seems that’s when this event is created. It’s unlikely to pop up too often, but still potentially useful to know. Firewall events The firewall is in charge of allowing or denying traffic based on its source and destination and the connection type. First up, here the the events that the Technicolor TG582n generates when somebody makes changes to its firewall rules. As you can see, they’re fairly self-explanatory. FIREWALL event (x of x): created rules FIREWALL event (x of x): modified rules FIREWALL event (x of x): deleted rules As you might suspect, these are generated when firewall rules are created, modified, and deleted respectively. One thing to watch out for with these, however, is that all three events seem to be generated in this order when a connection to the internet is established. So don’t be surprised if you see them crop up at points in the logs that you weren’t expecting them if the router was connecting to your ISP. Their effect will also require some investigation, as they don’t actually state which rules were changed. Next, let’s look at the firewall in action. In the week the router was active, the firewall sprung into action on the following three occasions, all of which related to internet control message protocol (ICMP) traffic. FIREWALL replay check (&amp;lt;x&amp;gt; of &amp;lt;x&amp;gt;): Protocol: ICMP Src ip: &amp;lt;source_ip&amp;gt; Dst ip: &amp;lt;destination_ip&amp;gt; Type: Destination Unreachable Code: Port Unreacheable FIREWALL icmp check (&amp;lt;x&amp;gt; of &amp;lt;x&amp;gt;): Protocol: ICMP Src ip: &amp;lt;source_ip&amp;gt; Dst ip: &amp;lt;destination_ip&amp;gt; Type: Destination Unreachable Code: Port Unreacheable FIREWALL icmp check (&amp;lt;x&amp;gt; of &amp;lt;x&amp;gt;): Protocol: ICMP Src ip: &amp;lt;source_ip&amp;gt; Dst ip: &amp;lt;destination_ip&amp;gt; Type: Echo Reply Code: 0 Unfortunately there’s no authority on what these actually mean. I’d expect a “replay check” to attempt to stop replay attacks, but the leading theory on the forums seems to be that this event means the firewall has prevented your router from providing a response to an ICMP ping from an attacker performing reconnaissance and attempting to discover information about your network. I have, however, also seen this occurring on outbound traffic to DNS servers from my Pi-hole, so your guess is as good as mine and any additional information anyone might be able to share would be appreciated. Intrusion detection system (IDS) events There’s a reason they say to start with your home network if you want to learn about cyber security. Looking through the IDS log will give you a nice insight into all the potentially nasty stuff targeting your network and give you a newfound appreciation for all the work your little Technicolor TG582n does. IDS dos parser : idp flood (1 of 1) : &amp;lt;source_ip&amp;gt; &amp;lt;destination_ip&amp;gt; 0801 UDP &amp;lt;source_port&amp;gt;-&amp;gt;&amp;lt;destination_port&amp;gt; IDS rate parser : tcp rate limiting (1 of 1) : &amp;lt;source_ip&amp;gt; &amp;lt;destination_ip&amp;gt; 0040 TCP &amp;lt;source_port&amp;gt;-&amp;gt;&amp;lt;destination_port&amp;gt; [S.....] seq 100 win 1024 IDS scan parser : tcp port scan: &amp;lt;destination_ip&amp;gt; scanned at least 10 ports at &amp;lt;destination_ip&amp;gt;. (1 of 1) : &amp;lt;source_ip&amp;gt; &amp;lt;destination_ip&amp;gt; 0040 TCP &amp;lt;source_port&amp;gt;-&amp;gt;&amp;lt;destination_port&amp;gt; [...R..] seq 11694198 win 0 IDS scan parser : udp port scan: &amp;lt;source_ip&amp;gt; scanned at least 20 ports at &amp;lt;destination_ip&amp;gt;. (1 of 1) : &amp;lt;source_ip&amp;gt; &amp;lt;destination_ip&amp;gt; 0441 UDP &amp;lt;source_port&amp;gt;-&amp;gt;&amp;lt;destination_port&amp;gt; IDS scan parser : tcp syn scan: &amp;lt;source_ip&amp;gt; scanned at least 20 ports at &amp;lt;destination_ip&amp;gt;. (1 of 1) : &amp;lt;source_ip&amp;gt; &amp;lt;destination_ip&amp;gt; 0040 TCP &amp;lt;source_port&amp;gt;-&amp;gt;&amp;lt;destination_port&amp;gt; [S.....] seq 97417629 win 1024 IDS proto parser : tcp null port (1 of 1) : &amp;lt;source_ip&amp;gt; &amp;lt;destination_ip&amp;gt; 0040 TCP &amp;lt;source_port&amp;gt;-&amp;gt;&amp;lt;destination_port&amp;gt; [S.....] seq 2505992964 win 1024 The IDS appears to have detection rules for potential denial of service (DoS) attacks. In the first event, too many UDP packets were detected between the same IP addresses. This typically appears to be followed up by a UDP rate limiting event as the router attempts to protect the network against the perceived attack. What’s pretty cool is that this also appears to apply to outgoing traffic, so if your devices become infected and form part of a botnet they are prevented from spamming the attackers’ targets with packets. The second event in my sample concerns TCP rate limiting and in my logs was applied to an IP address from Russia. An IDS applies rate limiting when it receives a large number of connection requests from a particular IP address and applies a temporary block to avoid a denial of service (DoS) condition. Note that this wouldn’t stop a distributed denial of service (DDoS) attack, which achieves the same result by sending a smaller number of packets from each of a large number of IP addresses. Then we have various types of detected port scans - in my case detected from IP addresses belonging to organisations as varied as Akamai, Amazon, GoDaddy, and Twitch, as well as a few IP addresses that looked like Russian hackers. Not much you can do about that, but it’s interesting stuff nonetheless. Finally, we have a TCP null port packet detection (in my logs the destination port showed up as 0). I couldn’t find too much information about this, but it’s likely to be a sign that an attacker is crafting nonsensical packets in an attempt to elicit an abnormal response from the router. Example investigation using Technicolor TG582n events Where does knowing all this get you? Having visibility of your router events and understanding what they mean can help you to troubleshoot network issues and identify potential cyber attacks - anything from sophisticated intruders to neighbours hijacking your broadband connection. As an example of how the Technicolor TG582n’s event logs can come in useful, during the week I was running the router I noticed a potential problem. Like many others during the COVID-19 pandemic, I was working from home, and my Skype video calls would drop out seemingly randomly. I decided to do some digging in the new logs for any clues, and here’s what I found at around the time of one of my failed calls… IDS dos parser : udp flood (1 of 1): &amp;lt;my_ip&amp;gt; &amp;lt;company_server_ip&amp;gt; 0801 UDP &amp;lt;source_port&amp;gt;-&amp;gt;&amp;lt;destination_port&amp;gt; IDS rate parser : udp rate limiting (1 of 1): &amp;lt;my_ip&amp;gt; &amp;lt;company_server_ip&amp;gt; 1072 UDP &amp;lt;source_port&amp;gt;-&amp;gt;&amp;lt;destination_port&amp;gt; PPP link down (Internet) [&amp;lt;my_ip&amp;gt;] PPP CHAP Receive challenge (rhost = &amp;lt;host&amp;gt;) PPP CHAP Chap receive success : authentication ok PPP link up (Internet) [&amp;lt;my_ip&amp;gt;] My best theory is this: The router spotted the large number of UDP datagrams being sent between my system and the Skype server and assumed this was a DoS attack. To put a stop to it, it applied rate limiting to the connection, which disrupted the call. Somewhere along the line this upset something, and that something failing took the connection down, meaning I had to wait for the broadband connection to resume before signing back into Skype, reconnecting to the call, and giving my apologies. Unfortunately, there’s little that you could do about this particular issue. The Technicolor TG582n gives you the option of turning the IDS on or off, and there is no configuration to be done beyond that - you’re either protected or you’re not. I suppose that means I should be glad that I’ve since upgraded. Contribute Event enumeration without proper documentation is often very hit-and-miss. I left the Technicolor TG582n router running for about a week to generate as many different events as possible, but if a certain type of event simply didn’t occur, it won’t have shown up in my analysis. If you have important and/or interesting events to add to this list, please get in touch via the links below and I’ll add them in (with credit!).</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mattcasmith.net/wp-content/uploads/2020/07/technicolor-tg582n-router.jpg" /><media:content medium="image" url="https://mattcasmith.net/wp-content/uploads/2020/07/technicolor-tg582n-router.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Welcome to a new website with a new philosophy</title><link href="https://mattcasmith.net/2020/06/30/new-website-new-philosophy/" rel="alternate" type="text/html" title="Welcome to a new website with a new philosophy" /><published>2020-07-04T00:00:00+01:00</published><updated>2020-07-04T00:00:00+01:00</updated><id>https://mattcasmith.net/2020/06/30/new-website-new-philosophy%20-%20Copy</id><content type="html" xml:base="https://mattcasmith.net/2020/06/30/new-website-new-philosophy/">&lt;p&gt;You may have noticed that things have changed around here - I built a new website, following the ethos that it should be as clear, lightweight, and fast as possible while respecting visitors’ privacy by keeping outside scripts and tracking to a minimum. In this post I take you through the process of designing and building the new site, from the initial inspiration to the end product you see today.&lt;/p&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;I read a lot of books during the COVID-19 lockdown. These ranged from one of the best novels I’ve ever read (&lt;em&gt;South of the Border, West of the Sun&lt;/em&gt; by Haruki Murakami) to some more relaxing non-fiction (&lt;em&gt;Blood, Sweat, and Pixels&lt;/em&gt; by Jason Schreier). But the pick of the bunch, and the one that has inspired me the most, is &lt;em&gt;Chaos Monkeys: Mayhem and Mania Inside the Silicon Valley Machine&lt;/em&gt;, which charts Antonio Garcia Martinez’s journey from Goldman Sachs to start-up founder to Facebook.&lt;/p&gt;

&lt;p&gt;The value of this book goes beyond what is physically held within its pages. Martinez referenced so many Googlable concepts, companies, people, and blogs that the thing took me about twice as long to read as any other book (perhaps the best among these was Paul Graham’s blog post &lt;a href=&quot;http://www.paulgraham.com/start.html&quot; target=&quot;_blank&quot;&gt;How to Start a Startup&lt;a&gt;&lt;/a&gt;, which Martinez described as “a crack-like gateway drug to the startup addiction”).&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Without a doubt the most valuable outcome of reading Martinez’s memoir, however, was that it reconnected me with &lt;a href=&quot;https://news.ycombinator.com/&quot; target=&quot;_blank&quot;&gt;Hacker News&lt;/a&gt;. Hacker News is a website run by the start-up accelerator Y Combinator. It functions something like Reddit, with hackers (read: people who like to code and make stuff, not hoodie-wearing, basement-dwelling script kiddies) posting links and upvoting useful content.&lt;/p&gt;

&lt;p&gt;By proxy, reconnecting with Hacker News meant reconnecting with the wonderful world of personal blogs run by techy people. I always try to pick up on these because they offer more inspiration and insight than commercial websites, but on the regular internet links to them are few and far between - something I’m acutely aware of with my own blog, which occasionally receives thousands of views in a short space of time thanks to Reddit posts, but does not do too well via search.&lt;/p&gt;

&lt;p&gt;Another big influence on the project was a series of blog posts I read on the concept of web bloat, including the transcript of Maciej Ceglowski’s talk &lt;a href=&quot;https://idlewords.com/talks/website_obesity.htm&quot; target=&quot;_blank&quot;&gt;The Website Obesity Crisis&lt;/a&gt;, which laments all the unnecessary additions to web pages that slow everything down and reduce compatibility without tangible benefit to the user. This leads to short news article pages that have bigger file sizes than the full text of &lt;em&gt;War and Peace&lt;/em&gt;, and misguided initiatives like Google’s Accelerated Mobile Pages (AMP) that speed up page loads but are still bloated and only serve to tighten big tech’s stranglehold on the internet.&lt;/p&gt;

&lt;p&gt;I had been mulling a change of platform - or rather a change away from my previous platform - for quite some time. After all, I am a cyber security professional, and for all its merits WordPress (or at least its plethora of poorly-coded plug-ins) sprouts as many vulnerabilities each month as the most detested corporate software out there. Add to that the overhead of dynamically generating every page as it is requested, which isn’t strictly necessary for a blog that is updated at most once per month, and it was clear that there was a better, more efficient way to do things.&lt;/p&gt;

&lt;h3 id=&quot;objectives&quot;&gt;Objectives&lt;/h3&gt;

&lt;p&gt;With that, I decided to take some inspiration from these small hacker blogs and build something new. But before I started, I needed to think carefully about exacly what I wanted to achieve and how I would do it. The following is a summary of what I came up with, embellished with the wisdom of hindsight:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;The site should serve lightweight, static pages.&lt;/strong&gt; In the interest of speed and efficiency, it was time to say goodbye to dynamically generated pages like those served by WordPress. They just take too long when good old HTML and CSS could do just as good a job by themselves.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;The site should give me control.&lt;/strong&gt; I’m a (fairly) competent person. I don’t need to be restricted by WordPress themes to avoid breaking my website. If I want to add new page elements or try out new features I should have the freedom to do so without worrying about how they fit into a content management system’s ecosystem.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;The site should scale back user tracking.&lt;/strong&gt; At various points in the past I’ve used Google Analytics and Jetpack to count visits. I’m still interested in how many people read my blog posts, but those solutions gave me more analytics than I would ever need, and stripping that bloat away could also negate the need for an ugly, annoying EU cookie notice.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;The site should save me money.&lt;/strong&gt; I’d been stuck with the same web hosting provider since 2012. To be fair they were relatively cheap, but when I needed support it was often sub-par and I frequently had to nag them to implement basic things like PHP updates. For the new website I’d be keeping an eye out for a new host, potentially even with a free platform that would support such a basic site.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With those broad goals in mind, I grabbed a pen and paper and spent some of my early time in lockdown sketching out what such a website might look like and listing ideas for how to satisfy my self-imposed requirements. After a little thinking and a bit of research, I had a plan.&lt;/p&gt;

&lt;h3 id=&quot;building-the-site&quot;&gt;Building the site&lt;/h3&gt;

&lt;p&gt;My initial idea to scratch my minimalist itch was to develop a series of Python scripts that would take data from text files, format them according to some HTML templates, and publish them to my web server. Then I discovered &lt;a href=&quot;https://jekyllrb.com/&quot; target=&quot;_blank&quot;&gt;Jekyll&lt;/a&gt;, which already did all of that - and it’s much better, and has many more features, than what I would have developed. What’s not to love about open source?&lt;/p&gt;

&lt;p&gt;So I downloaded it, got it running on Linux for Windows, and built the website you’re now reading. While it is a little more complicated than this makes it sound (Jekyll lets you store common elements in separate files and call them, and uses WordPress-style loops for posts, categories, and page content), the page you’re reading now is pure HTML and CSS, lovingly crafted from the ground up with the goal of staying as minimalist as possible. After running some page load tests, I think I’ve succeeded there.&lt;/p&gt;

&lt;p&gt;There are some cool features in here that I’m quite proud of. For a start, the site is responsive and looks great on mobile (the way the homepage achieves this is slightly hacky, but I’ll probably revisit that later). It also respects your preference for light or dark mode and displays the site in the appropriate colours (I use dark mode myself, so if there are light mode bugs I haven’t spotted, please let me know).&lt;/p&gt;

&lt;p&gt;Is it perfect? No. Every so often I spot a styling bug, the meta side of things could probably do with a once over, and there are definitely some messy elements to the code that I’d like to come up with more elegant solutions for in future. But in the spirit of moving fast and breaking things, the minimum viable product you see before you functions perfectly well in displaying information provided by me to you, the reader.&lt;/p&gt;

&lt;p&gt;One other area where I could be more efficient is my use of Jekyll. Being new to the whole thing, I learnt how it functions as I built the site, which is fine, but means there are probably a lot of things I would do differently now I’m more experienced. The great thing about Jekyll, however, is that because it builds static HTML pages, the output is all that matters for the most part, and poor input isn’t going to introduce any security vulnerabilities to the website because… well, there’s nothing to hack.&lt;/p&gt;

&lt;h3 id=&quot;hosting-the-site&quot;&gt;Hosting the site&lt;/h3&gt;

&lt;p&gt;Now that I had something to share with the world, I needed somewhere to share it from. A bunch of HTML pages could be hosted anywhere, and the easiest thing to do would have been to stick with my previous hosting provider. But by chance I came across a discussion about &lt;a href=&quot;https://pages.github.com/&quot; target=&quot;_blank&quot;&gt;GitHub Pages&lt;/a&gt; - a free platform for personal and project sites - and thought it sounded like a great solution to my problem.&lt;/p&gt;

&lt;p&gt;With GitHub Pages, I could save some money while taking a bet that Microsoft-owned servers would be faster and more reliable than my previous provider’s. I could use my own domain, and the transition even gave me a security boost as my domain and my site files are now behind separate 2FA-enabled logins.&lt;/p&gt;

&lt;p&gt;Setup, I’ll admit, was a little fiddly. GitHub Pages is not terribly well documented besides some basic instructions, and it seems to take a while to propagate once you turn it on. Eventually I got there, however, and the pain of the initial configuration is likely to be worth the ease with which I can publish new blog posts and other changes - simply by committing changes to a GitHub repository.&lt;/p&gt;

&lt;h3 id=&quot;adapting-my-content&quot;&gt;Adapting my content&lt;/h3&gt;

&lt;p&gt;One slightly time-consuming task was updating all my WordPress content to fit the new Jekyll site. The &lt;a href=&quot;https://wordpress.org/plugins/jekyll-exporter/&quot; target=&quot;_blank&quot;&gt;Jekyll Exporter plug-in&lt;/a&gt; was invaluable in this, saving me a lot of time manually copying posts into markdown by exporting all my WordPress posts into a Jekyll-friendly format… mostly.&lt;/p&gt;

&lt;p&gt;The work that remained was still tedious. WordPress had automatically replaced all images in the body text of my posts with source addresses on its content delivery network, so I needed to replace them with the URLs of the images on my web server. Also, I’d been using a plug-in to highlight code on my WordPress site, so I needed to go through all my programming posts and wrap the code in the Jekyll tags that would apply the right formatting. This wasn’t a difficult task, but it was long-winded.&lt;/p&gt;

&lt;p&gt;My internet minimalism didn’t stop at the design, however. I’m also more conscious than ever that I want every page on my website to offer value to readers. This doesn’t mean &lt;a href=&quot;/category/off-topic.html&quot;&gt;the Off-Topic category&lt;/a&gt; is going anywhere - value isn’t limited by subject. But at some points in the past I’ve been very determined to write a blog post every two weeks, or every month, and when inspiration didn’t strike this led to some bland posts. I removed these, keeping only what I see as the higher-value posts, and I will endeavour to ensure all future posts are based around either an interesting take or useful technical content.&lt;/p&gt;

&lt;h3 id=&quot;tracking-the-site&quot;&gt;Tracking the site&lt;/h3&gt;

&lt;p&gt;So what about the elephant in the room: tracking? As I previously mentioned, some of the data provided by Google Analytics and Jetpack was useful, but it went far beyond what I needed and their use of cookies meant I needed a warning on the site to comply with EU law - something that jarred with my minimalist objective. But what else was out there? Would I need to code a tracker myself?&lt;/p&gt;

&lt;p&gt;Over a period of weeks a few different analytics start-ups flaunted their offerings on Hacker News, but they were all aimed at enterprises and priced accordingly, meaning that an analytics implementation would set me back the money I was saving on hosting (and then some). It was looking like I’d need to bite the bullet and go back to Google if I wanted any insight into which of my posts visitors enjoyed.&lt;/p&gt;

&lt;p&gt;Enter &lt;a href=&quot;https://www.goatcounter.com/&quot; target=&quot;_blank&quot;&gt;Goat Counter&lt;/a&gt;, which really saved the day on this. This open source analytics platform is free for personal use (although I’ll still probably buy the creators a coffee later on, once I’m sure it’s for me), and it uses a single JavaScript file to generate simple statistics: pages visited, referrers, countries, browsers, screeen size, and so on. It’s just the level of detail I need to keep improving the site, and it’s delivered with barely any tradeoff in terms of speed or user privacy. There are no cookies, either!&lt;/p&gt;

&lt;h3 id=&quot;final-thoughts&quot;&gt;Final thoughts&lt;/h3&gt;

&lt;p&gt;All in all, this has worked out pretty well. The site loads quickly, and the process for creating a new post is both more straightforward and more flexible than it was under WordPress. It looks something like this:&lt;/p&gt;

&lt;p&gt;        &lt;strong&gt;1.&lt;/strong&gt; Write post in Markdown format&lt;br /&gt;
        &lt;strong&gt;2.&lt;/strong&gt; Run Jekyll to generate HTML pages&lt;br /&gt;
        &lt;strong&gt;3.&lt;/strong&gt; Copy HTML to GitHub repository folder&lt;br /&gt;
        &lt;strong&gt;4.&lt;/strong&gt; Push update to GitHub to publish&lt;/p&gt;

&lt;p&gt;The additional benefit of no paid hosting only sweetens the deal, and means that all I need to pay for is my domain. And I don’t even need to remember to back up my website anymore, because: a) it’s stored on GitHub, a more reliable platform than my previous provider; and b) the latest HTML files generated by Jekyll will always be on my hard drive, where they will be automatically picked up by my usual backups.&lt;/p&gt;

&lt;p&gt;It’s taken a lot of work, and probably would have taken a lot longer if it wasn’t for the extra time afforded by the COVID-19 lockdown, but overall I think I can call the project a success. I now have a light, fast-loading website that respects users’ privacy and better reflects who I am.&lt;/p&gt;

&lt;p&gt;There are changes to be made and features I want to add, but the beauty of the Jekyll/GitHub setup is that I can continue to develop at my own pace and the site will still function. I’m also interested in any feedback visitors might have about the change, so if you have any thoughts, ideas, or suggestions for updates, please do use the links below to get in touch.&lt;/p&gt;</content><author><name>mattcasmith</name></author><category term="HTML" /><category term="CSS" /><category term="Web" /><category term="Internet" /><category term="Blogging" /><summary type="html">You may have noticed that things have changed around here - I built a new website, following the ethos that it should be as clear, lightweight, and fast as possible while respecting visitors’ privacy by keeping outside scripts and tracking to a minimum. In this post I take you through the process of designing and building the new site, from the initial inspiration to the end product you see today. Background I read a lot of books during the COVID-19 lockdown. These ranged from one of the best novels I’ve ever read (South of the Border, West of the Sun by Haruki Murakami) to some more relaxing non-fiction (Blood, Sweat, and Pixels by Jason Schreier). But the pick of the bunch, and the one that has inspired me the most, is Chaos Monkeys: Mayhem and Mania Inside the Silicon Valley Machine, which charts Antonio Garcia Martinez’s journey from Goldman Sachs to start-up founder to Facebook. The value of this book goes beyond what is physically held within its pages. Martinez referenced so many Googlable concepts, companies, people, and blogs that the thing took me about twice as long to read as any other book (perhaps the best among these was Paul Graham’s blog post How to Start a Startup, which Martinez described as “a crack-like gateway drug to the startup addiction”). Without a doubt the most valuable outcome of reading Martinez’s memoir, however, was that it reconnected me with Hacker News. Hacker News is a website run by the start-up accelerator Y Combinator. It functions something like Reddit, with hackers (read: people who like to code and make stuff, not hoodie-wearing, basement-dwelling script kiddies) posting links and upvoting useful content. By proxy, reconnecting with Hacker News meant reconnecting with the wonderful world of personal blogs run by techy people. I always try to pick up on these because they offer more inspiration and insight than commercial websites, but on the regular internet links to them are few and far between - something I’m acutely aware of with my own blog, which occasionally receives thousands of views in a short space of time thanks to Reddit posts, but does not do too well via search. Another big influence on the project was a series of blog posts I read on the concept of web bloat, including the transcript of Maciej Ceglowski’s talk The Website Obesity Crisis, which laments all the unnecessary additions to web pages that slow everything down and reduce compatibility without tangible benefit to the user. This leads to short news article pages that have bigger file sizes than the full text of War and Peace, and misguided initiatives like Google’s Accelerated Mobile Pages (AMP) that speed up page loads but are still bloated and only serve to tighten big tech’s stranglehold on the internet. I had been mulling a change of platform - or rather a change away from my previous platform - for quite some time. After all, I am a cyber security professional, and for all its merits WordPress (or at least its plethora of poorly-coded plug-ins) sprouts as many vulnerabilities each month as the most detested corporate software out there. Add to that the overhead of dynamically generating every page as it is requested, which isn’t strictly necessary for a blog that is updated at most once per month, and it was clear that there was a better, more efficient way to do things. Objectives With that, I decided to take some inspiration from these small hacker blogs and build something new. But before I started, I needed to think carefully about exacly what I wanted to achieve and how I would do it. The following is a summary of what I came up with, embellished with the wisdom of hindsight: The site should serve lightweight, static pages. In the interest of speed and efficiency, it was time to say goodbye to dynamically generated pages like those served by WordPress. They just take too long when good old HTML and CSS could do just as good a job by themselves. The site should give me control. I’m a (fairly) competent person. I don’t need to be restricted by WordPress themes to avoid breaking my website. If I want to add new page elements or try out new features I should have the freedom to do so without worrying about how they fit into a content management system’s ecosystem. The site should scale back user tracking. At various points in the past I’ve used Google Analytics and Jetpack to count visits. I’m still interested in how many people read my blog posts, but those solutions gave me more analytics than I would ever need, and stripping that bloat away could also negate the need for an ugly, annoying EU cookie notice. The site should save me money. I’d been stuck with the same web hosting provider since 2012. To be fair they were relatively cheap, but when I needed support it was often sub-par and I frequently had to nag them to implement basic things like PHP updates. For the new website I’d be keeping an eye out for a new host, potentially even with a free platform that would support such a basic site. With those broad goals in mind, I grabbed a pen and paper and spent some of my early time in lockdown sketching out what such a website might look like and listing ideas for how to satisfy my self-imposed requirements. After a little thinking and a bit of research, I had a plan. Building the site My initial idea to scratch my minimalist itch was to develop a series of Python scripts that would take data from text files, format them according to some HTML templates, and publish them to my web server. Then I discovered Jekyll, which already did all of that - and it’s much better, and has many more features, than what I would have developed. What’s not to love about open source? So I downloaded it, got it running on Linux for Windows, and built the website you’re now reading. While it is a little more complicated than this makes it sound (Jekyll lets you store common elements in separate files and call them, and uses WordPress-style loops for posts, categories, and page content), the page you’re reading now is pure HTML and CSS, lovingly crafted from the ground up with the goal of staying as minimalist as possible. After running some page load tests, I think I’ve succeeded there. There are some cool features in here that I’m quite proud of. For a start, the site is responsive and looks great on mobile (the way the homepage achieves this is slightly hacky, but I’ll probably revisit that later). It also respects your preference for light or dark mode and displays the site in the appropriate colours (I use dark mode myself, so if there are light mode bugs I haven’t spotted, please let me know). Is it perfect? No. Every so often I spot a styling bug, the meta side of things could probably do with a once over, and there are definitely some messy elements to the code that I’d like to come up with more elegant solutions for in future. But in the spirit of moving fast and breaking things, the minimum viable product you see before you functions perfectly well in displaying information provided by me to you, the reader. One other area where I could be more efficient is my use of Jekyll. Being new to the whole thing, I learnt how it functions as I built the site, which is fine, but means there are probably a lot of things I would do differently now I’m more experienced. The great thing about Jekyll, however, is that because it builds static HTML pages, the output is all that matters for the most part, and poor input isn’t going to introduce any security vulnerabilities to the website because… well, there’s nothing to hack. Hosting the site Now that I had something to share with the world, I needed somewhere to share it from. A bunch of HTML pages could be hosted anywhere, and the easiest thing to do would have been to stick with my previous hosting provider. But by chance I came across a discussion about GitHub Pages - a free platform for personal and project sites - and thought it sounded like a great solution to my problem. With GitHub Pages, I could save some money while taking a bet that Microsoft-owned servers would be faster and more reliable than my previous provider’s. I could use my own domain, and the transition even gave me a security boost as my domain and my site files are now behind separate 2FA-enabled logins. Setup, I’ll admit, was a little fiddly. GitHub Pages is not terribly well documented besides some basic instructions, and it seems to take a while to propagate once you turn it on. Eventually I got there, however, and the pain of the initial configuration is likely to be worth the ease with which I can publish new blog posts and other changes - simply by committing changes to a GitHub repository. Adapting my content One slightly time-consuming task was updating all my WordPress content to fit the new Jekyll site. The Jekyll Exporter plug-in was invaluable in this, saving me a lot of time manually copying posts into markdown by exporting all my WordPress posts into a Jekyll-friendly format… mostly. The work that remained was still tedious. WordPress had automatically replaced all images in the body text of my posts with source addresses on its content delivery network, so I needed to replace them with the URLs of the images on my web server. Also, I’d been using a plug-in to highlight code on my WordPress site, so I needed to go through all my programming posts and wrap the code in the Jekyll tags that would apply the right formatting. This wasn’t a difficult task, but it was long-winded. My internet minimalism didn’t stop at the design, however. I’m also more conscious than ever that I want every page on my website to offer value to readers. This doesn’t mean the Off-Topic category is going anywhere - value isn’t limited by subject. But at some points in the past I’ve been very determined to write a blog post every two weeks, or every month, and when inspiration didn’t strike this led to some bland posts. I removed these, keeping only what I see as the higher-value posts, and I will endeavour to ensure all future posts are based around either an interesting take or useful technical content. Tracking the site So what about the elephant in the room: tracking? As I previously mentioned, some of the data provided by Google Analytics and Jetpack was useful, but it went far beyond what I needed and their use of cookies meant I needed a warning on the site to comply with EU law - something that jarred with my minimalist objective. But what else was out there? Would I need to code a tracker myself? Over a period of weeks a few different analytics start-ups flaunted their offerings on Hacker News, but they were all aimed at enterprises and priced accordingly, meaning that an analytics implementation would set me back the money I was saving on hosting (and then some). It was looking like I’d need to bite the bullet and go back to Google if I wanted any insight into which of my posts visitors enjoyed. Enter Goat Counter, which really saved the day on this. This open source analytics platform is free for personal use (although I’ll still probably buy the creators a coffee later on, once I’m sure it’s for me), and it uses a single JavaScript file to generate simple statistics: pages visited, referrers, countries, browsers, screeen size, and so on. It’s just the level of detail I need to keep improving the site, and it’s delivered with barely any tradeoff in terms of speed or user privacy. There are no cookies, either! Final thoughts All in all, this has worked out pretty well. The site loads quickly, and the process for creating a new post is both more straightforward and more flexible than it was under WordPress. It looks something like this:         1. Write post in Markdown format         2. Run Jekyll to generate HTML pages         3. Copy HTML to GitHub repository folder         4. Push update to GitHub to publish The additional benefit of no paid hosting only sweetens the deal, and means that all I need to pay for is my domain. And I don’t even need to remember to back up my website anymore, because: a) it’s stored on GitHub, a more reliable platform than my previous provider; and b) the latest HTML files generated by Jekyll will always be on my hard drive, where they will be automatically picked up by my usual backups. It’s taken a lot of work, and probably would have taken a lot longer if it wasn’t for the extra time afforded by the COVID-19 lockdown, but overall I think I can call the project a success. I now have a light, fast-loading website that respects users’ privacy and better reflects who I am. There are changes to be made and features I want to add, but the beauty of the Jekyll/GitHub setup is that I can continue to develop at my own pace and the site will still function. I’m also interested in any feedback visitors might have about the change, so if you have any thoughts, ideas, or suggestions for updates, please do use the links below to get in touch.</summary></entry><entry><title type="html">Why virtual cyber security conferences should be the new normal</title><link href="https://mattcasmith.net/2020/05/02/virtual-cyber-security-conferences-new-normal/" rel="alternate" type="text/html" title="Why virtual cyber security conferences should be the new normal" /><published>2020-05-02T12:05:40+01:00</published><updated>2020-05-02T12:05:40+01:00</updated><id>https://mattcasmith.net/2020/05/02/virtual-cyber-security-conferences-new-normal</id><content type="html" xml:base="https://mattcasmith.net/2020/05/02/virtual-cyber-security-conferences-new-normal/">&lt;p&gt;It’s not just TV presenters who have been broadcasting from their homes during the COVID-19 lockdown. Cyber security conferences have also gone virtual, opening them up to attendees who would otherwise be unable to benefit.&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;Information security conferences are usually few and far between, at least in the UK. In my experience they come around now and again, generally cost an arm and a leg to attend, and mostly take a corporate perspective on things, focusing on CISO-level issues. With a few exceptions, we’re mostly talking Black Hat’s shirts and trousers rather than Def Con’s uniform of black t-shirts and shorts.&lt;/p&gt;

&lt;p&gt;A lot of the cooler, smaller, more informal cons seem to happen over in the USA. It’s great that they exist, and I’d love to visit some of them one day, but to do so would require time off work and substantial costs for flights and hotels (even more so if they’re hosted in Las Vegas).&lt;/p&gt;

&lt;p&gt;Then came the COVID-19 pandemic and all of that changed. With group gatherings no longer allowed, these events were pushed out of the meatspace and some of them took up a new home online.&lt;/p&gt;

&lt;p&gt;My awareness of these new, free virtual cons began with &lt;a href=&quot;https://twitter.com/introseccon&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;IntroSecCon&lt;/a&gt; – an event run for those starting out in cyber security that aimed to cover the basics of various technical disciplines that are usually glossed over at mainstream conferences. This struck me as a great idea and something that I wish had been running a few years ago when I joined the industry.&lt;/p&gt;

&lt;p&gt;I was familiar with much of the technical content of IntroSecCon, but what kept me watching was the general atmosphere of the conference and the people involved. Where else, for example, would I get to watch Ming Chow – a member of the Def Con Wall of Sheep team – deliver packet analysis 101?&lt;/p&gt;

&lt;p&gt;The speaker lineup probably helped, but sitting on my bed watching the talks on the TV reminded me of August last year, when I watched some of the busier &lt;a href=&quot;https://mattcasmith.net/2019/08/26/im-back-def-con-inspired-hacking/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Def Con&lt;/a&gt; talks from my hotel room in Las Vegas, thinking about the potential of what I was learning. In fact, straight after IntroSecCon I dug out my second NIC and refreshed my memory by capturing some traffic from my home WiFi network.&lt;/p&gt;

&lt;p&gt;But the lockdown isn’t over yet, and neither are the virtual conferences. One noteworthy event – Deserted Island Devops, which I wasn’t aware of until it was over – brought devops presentations to Animal Crossing: New Horizons. I didn’t realise what had happened before I saw a picture of &lt;a href=&quot;https://twitter.com/chriseng/status/1255862302366216197&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;a virtual Ian Coldwater giving a talk at the front of an in-game conference hall&lt;/a&gt; on Twitter!&lt;/p&gt;

&lt;p&gt;Next up, I’m looking forward to &lt;a href=&quot;https://www.magnetvirtualsummit.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Magnet Forensics’ Virtual Summit 2020&lt;/a&gt;, which essentially consists of two DFIR webinars per day across most of May. I’ve signed up for talks on memory analysis, ransomware, and email-delivered malware among other topics.&lt;/p&gt;

&lt;p&gt;What’s so great about this new generation of conferences is their accessibility. I don’t need to take time off work, I don’t need to travel, and in most cases I don’t need to pay a penny to learn about cyber security from some of the best minds in the industry.&lt;/p&gt;

&lt;p&gt;For that reason, I hope this trend continues and these events are still put on far beyond the end of the COVID-19 lockdown. That’s not to say we should move all in-person conferences online (certain types of networking only happen in person), but we could all really benefit from the educational content, digital networking opportunities, and sense of community and innovation that virtual cons foster.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Photo by &lt;a href=&quot;https://unsplash.com/@cwmonty?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText&quot;&gt;Chris Montgomery&lt;/a&gt; on &lt;/em&gt;&lt;a href=&quot;https://unsplash.com/s/photos/webcam?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText&quot;&gt;&lt;em&gt;Unsplash&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;</content><author><name>mattcasmith</name></author><category term="Conferences" /><category term="Cyber Security" /><category term="Events" /><category term="Learning" /><summary type="html">It’s not just TV presenters who have been broadcasting from their homes during the COVID-19 lockdown. Cyber security conferences have also gone virtual, opening them up to attendees who would otherwise be unable to benefit.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mattcasmith.net/wp-content/uploads/2020/05/zoom.jpg" /><media:content medium="image" url="https://mattcasmith.net/wp-content/uploads/2020/05/zoom.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>